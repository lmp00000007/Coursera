1
00:00:01,019 --> 00:00:06,056
那么，之前讲的栈的基本数组实现具有需要

2
00:00:06,056 --> 00:00:11,610
客户端事先提供栈的最大容量的缺点。现在

3
00:00:11,610 --> 00:00:17,020
我们来看解决这个问题的技术。我们没有

4
00:00:17,020 --> 00:00:22,033
严格按照API的要求。API就是要求我们能够建立一个栈

5
00:00:22,033 --> 00:00:27,021
并且能够增长或者缩小到任意大小。那么我们

6
00:00:27,021 --> 00:00:31,632
应该怎么做呢？你首先会想到的也许是当客户端入栈新元素时

7
00:00:31,632 --> 00:00:36,530
将栈的大小增加1，当出栈时

8
00:00:36,530 --> 00:00:41,225
将栈的大小减小1。代码实现不难，但是不值得这么做，因为这么做

9
00:00:41,225 --> 00:00:46,533
开销太大了。因为你必须创建大小大一个元素的

10
00:00:46,533 --> 00:00:52,290
新的数组，然后把所有的元素复制到新的数组中。所以如果栈大小为N-1

11
00:00:52,290 --> 00:00:58,361
插入N个元素需要的时间和N成正比

12
00:00:58,361 --> 00:01:04,148
如果栈大小为N-2，需要正比于N-1的时间。所以前N个元素需要的时间就是对

13
00:01:04,148 --> 00:01:10,953
前N个整数求和，我们知道这大约是N^2 / 2。往栈里插入N个元素

14
00:01:10,953 --> 00:01:16,623
需要平方时间，我们已经看到过很多次，这样的性能对于

15
00:01:16,623 --> 00:01:22,693
巨大的问题是不可接受的。那么，调整大小是个挑战

16
00:01:22,693 --> 00:01:29,227
但要通过某种方式确保它并不会经常发生。处理这个问题

17
00:01:29,227 --> 00:01:35,995
有个著名的方法叫反复倍增，当数组填满时

18
00:01:35,995 --> 00:01:43,088
建立一个大小翻倍的新数组，然后将所有元素复制过去，我们就不会

19
00:01:43,088 --> 00:01:50,773
那么频繁地创建新数组。这就是那个方法的实现。从大小为1的

20
00:01:50,773 --> 00:01:57,049
数组开始。如果我们检测到N即栈中元素的个数与数组

21
00:01:57,049 --> 00:02:03,038
长度相等，则栈满了，那么我们就在插入元素之前

22
00:02:03,038 --> 00:02:09,066
将数组长度调整为两倍。我们如何调整为更大的数组呢？

23
00:02:09,323 --> 00:02:16,312
我们创建具有目标容量的新的数组，然后把

24
00:02:16,312 --> 00:02:22,803
当前栈复制到新数组的前一半，然后返回

25
00:02:23,029 --> 00:02:30,211
重新设置实例变量，我们的栈就有了更大的数组

26
00:02:30,211 --> 00:02:37,570
这样做导致如果你向一个具有这种

27
00:02:37,570 --> 00:02:43,675
数组表示的栈中插入N个元素，时间复杂度

28
00:02:43,675 --> 00:02:50,712
与N而不是N^2成正比。因为你只有在数组大小翻倍时

29
00:02:50,712 --> 00:02:57,203
才创建新的数组。而当数组翻倍时，你已经往栈里插入了

30
00:02:57,203 --> 00:03:04,514
那么多的元素。所以平均下来就像每次插入只需要一个操作

31
00:03:04,514 --> 00:03:10,977
所以，如果我们计算一下开销，插入前N个元素

32
00:03:10,977 --> 00:03:16,179
你不需要花费从1到N之和的时间，而是

33
00:03:16,179 --> 00:03:21,689
对二的幂从1到N求和

34
00:03:21,689 --> 00:03:27,284
这样，总的开销大约是3N。所以，先要访问数组一次，对于复制

35
00:03:27,284 --> 00:03:33,009
要访问两次。所以，要插入元素，大约需要访问数组三次

36
00:03:33,009 --> 00:03:38,623
这个图标是观察时间开销的另一种方式，表示出了实现

37
00:03:38,623 --> 00:03:43,883
入栈操作需要访问数组的次数。每次遇到2的幂，需要进行那么多次

38
00:03:43,883 --> 00:03:48,801
数组访问，但是从宏观上来看你是将那些元素放在栈上花去了那么多时间

39
00:03:48,801 --> 00:03:54,871
这叫做平摊分析。考虑开销时

40
00:03:54,871 --> 00:04:01,343
将总的开销平均给所有的操作。这是一个很好而且

41
00:04:01,574 --> 00:04:07,377
有用的平摊分析的例子，我们分析出了栈实现的效率

42
00:04:07,377 --> 00:04:12,402
出栈呢？我们需要考虑如何缩小数组

43
00:04:12,598 --> 00:04:17,589
我们也许这么考虑，当数组满了的时候将容量翻倍，那么当它

44
00:04:17,589 --> 00:04:23,074
只有一半满的时候，将容量缩减一半。我们不想让数组变得太空

45
00:04:23,074 --> 00:04:28,934
额，这个办法并不如我们所愿解决问题。因为有一种现象叫做

46
00:04:28,934 --> 00:04:34,553
抖动（thrashing）。如果客户端刚好反复交替入栈出栈入栈出栈

47
00:04:34,553 --> 00:04:40,208
当数组满了就会反复翻倍减半翻倍减半，并且

48
00:04:40,208 --> 00:04:45,308
每个操作都会新建数组，都要花掉正比与N的时间

49
00:04:45,308 --> 00:04:51,069
这样就会导致平方时间，我们不想这样

50
00:04:51,268 --> 00:04:56,810
有效的解决方案是直到数组变为1/4满的时候才将容量减半

51
00:04:56,810 --> 00:05:02,074
实现起来也很容易，我们只要测试数组是否为

52
00:05:02,074 --> 00:05:08,091
1/4满，如果是，则调整大小使其为半满。然后接下来，因为是半满的

53
00:05:08,091 --> 00:05:15,000
既可以插入元素让栈增长或者删除元素让栈变小

54
00:05:15,000 --> 00:05:21,009
而不需要再次进行调整数组大小的操作直到数组全满

55
00:05:21,009 --> 00:05:26,880
或者再次1/4满。所以这里的不变式是数组总是介于25%满与

56
00:05:26,880 --> 00:05:31,390
全满之间，这是第一点；第二，每次调整大小时

57
00:05:31,390 --> 00:05:37,887
开销已经在平摊给了每次入栈和出栈

58
00:05:37,887 --> 00:05:44,791
这里展示了我们的小的客户端例子中数组上的操作

59
00:05:44,791 --> 00:05:50,139
可以看到在开始时，数组大小从1倍增到2又到4

60
00:05:50,139 --> 00:05:55,736
但一旦到8，数组的大小则维持

61
00:05:55,736 --> 00:06:01,632
一段时间，直到数组中只有

62
00:06:01,816 --> 00:06:07,036
2个元素时才缩小到4，等等

63
00:06:07,036 --> 00:06:13,130
数组调整大小并不经常发生，但这是实现

64
00:06:13,394 --> 00:06:20,500
栈API的一种很有效的方式，客户端不需要

65
00:06:20,500 --> 00:06:27,707
提供栈的最大容量，但依然保证了我们使用

66
00:06:27,707 --> 00:06:34,110
的内存大小总是栈中实际元素个数的常数倍

67
00:06:34,110 --> 00:06:41,570
所以分析说明对于任意的操作序列，每个操作的

68
00:06:41,570 --> 00:06:48,896
平均运行时间与常数成正比。这里，存在最坏情况

69
00:06:48,896 --> 00:06:55,489
当栈容量翻倍时，需要正比于N的时间，所以性能

70
00:06:55,489 --> 00:07:01,048
不如我们想要的那么好，但是优势在于进行

71
00:07:01,048 --> 00:07:07,823
入栈出栈操作时非常快，入栈只需要访问数组

72
00:07:07,823 --> 00:07:13,470
并增加栈顶索引。对于大多数操作都很高效

73
00:07:13,681 --> 00:07:19,851
对于众多的客户端这是个很有效的权衡

74
00:07:19,851 --> 00:07:27,065
内存使用量呢？这是栈的内存用量分析

75
00:07:27,065 --> 00:07:35,113
实际上比链表使用更少的内存。内存用量在8N到

76
00:07:35,113 --> 00:07:42,528
32N之间，取决于数组有多满。这里只是计算了

77
00:07:42,528 --> 00:07:50,452
Java中数组占用的空间。同样地，这个分析只针对栈本身

78
00:07:50,452 --> 00:07:57,009
而不包括客户端上的字符串。那么使用

79
00:07:57,238 --> 00:08:01,906
可调整大小的数组与链表之间如何取舍呢？这是两种

80
00:08:01,906 --> 00:08:07,771
API相同的不同的实现，客户端可以互换使用。哪个更好呢？

81
00:08:07,771 --> 00:08:13,295
很多情形中，我们会有同一API的多种实现

82
00:08:13,295 --> 00:08:19,117
你需要根据客户端的性质选择

83
00:08:19,117 --> 00:08:24,520
合适的实现。对于链表，每个操作最坏情况下

84
00:08:24,520 --> 00:08:30,091
需要常数时间，这是有保障的。但是为了处理链接

85
00:08:30,091 --> 00:08:36,001
我们需要一些额外的时间和空间。所以链表实现会慢一些

86
00:08:36,232 --> 00:08:42,888
可调大小的数组实现有很好的分摊时间，所以整个过程

87
00:08:42,888 --> 00:08:48,514
总的平均效率不错，浪费更少的空间，对于每个操作

88
00:08:48,514 --> 00:08:53,946
也许有更快的实现，所以对于一些客户端，也许会有区别

89
00:08:53,946 --> 00:08:58,192
以下这样的情形你不会想用可调大小数组实现

90
00:08:58,192 --> 00:09:02,950
你有一架飞机进场等待降落

91
00:09:02,950 --> 00:09:06,929
你不想系统突然间不能高效运转

92
00:09:06,929 --> 00:09:11,403
或者互联网上的一个路由器，数据包以很高的速度涌进来

93
00:09:11,403 --> 00:09:15,312
你不想因为某个操作突然变得很慢而丢失

94
00:09:15,312 --> 00:09:19,314
一些数据。客户端就可以权衡，如果想要

95
00:09:19,314 --> 00:09:24,109
获得保证每个操作能够很快完成，就使用

96
00:09:24,109 --> 00:09:29,595
链表实现，如果不需要，只是关心总的时间

97
00:09:29,595 --> 00:09:34,684
可能就是用可调大小数组实现，因为总的

98
00:09:34,892 --> 00:09:40,379
时间会小得多，单个操作非常快

99
00:09:40,379 --> 00:09:49,271
所以，尽管只有这些简单的数据结构，我们都需要

100
00:09:49,271 --> 00:09:56,043
做很重要的权衡，在很多实际情形中真的会产生影响