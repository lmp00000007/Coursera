증가기준분석은 너무 중요한 주제라서 최근에 많은 연구들이 쏟아지고 있는데요, 잠깐 얘기해 보겠습니다. 저번 강의해서 얘기했던 것보다 조금 더 복잡한 면이 있습니다 첫째로는, 인풋에 따라 알고리즘의 성능 차이가 날 수 있습니다. 그래서 인풋 종류에 따라서 알고리즘을 분석하는 다양한 방법을 생각해 볼 수 있습니다. 러닝 타임은 최선의 케이스와 최악의 케이스 사이에 있을 겁니다. 최선의 케이스는 하계가됩니다. 하계는 러닝 타임이 항상 그 이상일 것이라는것을 보장해주며, 최악의 케이스는 가장 어려운 인풋인데요, 분석하는데 걸리는 러닝 타임이 항상 이 상계보다는 작다는걸 보장합니다. 그리고 많은 상황에서는 인풋이 랜덤이라고 생각합니다. 현재 푸는 문제에 있어서 랜덤이란 무슨뜻인지 정의할 모델이 필요한데요, 이게 가능한 상황이 많습니다, 그로인해 인풋의 분산이 높아도 퍼포먼스를 쉽게 예상할 수 있게해줍니다. 3-sum을 예로들면, 이건 항상 같은데요. 틸드 표기법을 쓰면, 알고리즘에 있어 유일한 변이는, 카운터가 증가하는 횟수입니다. 그건 낮은 차 항이라서 우리 분석에서는 신경쓸 필요가 없습니다. 바이너리 서치에 있어서, 바로 발견하셨다시피 최선의 케이스는 상수 시간이 걸리고, 평균과 최악의 케이스는 둘다 lnN입니다. 변동성이 높은 다른 경우 또한 있습니다. 인풋에 따른 다른 분석 방법이 있는데요. 실제 클라이언트가 풀려는 실제 문제에는 어떨까요? 알고리즘의 성능을 이해하기 위해서는 이 부분도 알아야 합니다. 성공적인 두 가지 접근법이 있습니다. 하나는 최악의 케이스를 염두해 둔 디자인입니다. 이로인해 알고리즘이 어느 상황에서도 빠른 성능을 보장합니다. 둘째는 랜덤화해서 어떤 확률적 보장에 의존하는 겁니다 강의를 진행하면서 두 경우를 모두 볼겁니다. 이런 증가도에 대한 고려들을, 저는 알고리즘 이론이라고 부릅니다. 3-sum과 같이 풀어야할 문제가 있을때 그게 얼마나 어려운지 알고 싶은게 이론의 목적입니다. 문제에 대한 최고의 알고리즘을 알고 싶습니다. 컴퓨터 공학자들이 여기에 쓰는 접근법으로는, 분석에 있어 세부사항을 최대한 억제하는겁니다. 그로인해 상수 계수만 가지고 러닝 타임을 분석합니다. 이것이 증가도분석의 목적입니다. 저는 또한 인풋 모델에 좌우되고 싶지도 않습니다. 그래서 최악 케이스을 염두한 설계에 집중합니다. 그 뒤에 단지 증가도만으로 알고리즘 성능을 설명할 수 있습니다. 사실 문제 풀이의 복잡성에 대해 알려주는 매우 엄격한 방식으로 가능합니다. 우리의 목적은 최악의 케이스를 발견함으로써 어떤 인풋에도 상수 계수안에서 특정 성능을 보장하는 최적의 알고리즘을 찾는것인데요. 또한 어떤 알고리즘 보다도 최적인 알고리즘을 찾고 싶습니다. 추후에 몇가지 예를 들겠습니다. 이런 분석을 위해 통상적으로 사용하는 표기법이 있는데요 빅 세타, 빅 오, 빅 오메가 표기법입니다. 여기 표기법이 있습니다. 빅 세타 표기법은 증가도를 표현합니다. 세타(N^2)는 N^2와 관련된 모든것을 나타냅니다. 상하계 모두 N^2형으로 이루어져있고, 그게 우리가 알고리즘을 분류할때 사용하는 겁니다. 빅 오 표기법은, 퍼포먼스의 상계를 나타냅니다 빅 오(N^2)가 나타내는 것은, N이 증가할때 임의의 상수 곱하기 N^2보다는 낮다는 겁니다. 빅 오메가는 하계를 의미하는데, N이 증가할때 N^2보다 크다는것을 나타냅니다. 위 세가지 표기법은 알고리즘 분류에 사용되는데, 추후에 보여드리겠습니다. 1,2,3-sum을 예로들면 쉽습니다. 우리 목적은 문제의 어려움을 정립해보고, 최적의 알고리즘을 개발하는 겁니다. 1-sum 문제는, 즉 배열에 0이 있나 찾는겁니다. 문제 난해성의 상계는 특정한 알고리즘으로 주어집니다. 예를 들면, 브루트포스(완전탐색) 는 배열의 모든 엔트리를 모두 검색하는데요, 다시말해 O(N)시간, 임의 상수 곱하기 N보다 작은 시간이 걸립니다. 최적 알고리즘의 러닝 타임은 O(N)이 되어야하는데요, 다시말하면, 이 특정 알고리즘은 최적 알고리즘의 러닝 타임의 상계를 줍니다. 이 경우에는, 하계를 발견하기도 쉬운데요 하계란, 어떤 알고리즘도 이보단 나을수 없다는걸 보여주죠. 1-sum에서는 배열의 모든 엔트리를 검색해야합니다. 하나라도 놓친다면, 그 엔트리가 0일지도 모르니까요. 다시말해, 최적의 알고리즘은 최소 임의 상수 곱하기 N의 러닝 타임을 가져야합니다. 다시말해 빅 오메가(N)으로 표현하죠. 이 경우에는, 상계와 하계가 같습니다. 그래서 상수곱 내에서는, 브르투 포스 알고리즘이 1-sum에 있어 최적이라는걸 증명합니다. 러닝 타임은 세타(N)이며, 오메가(N), O(N)과 같습니다. 이런 쉬운 문제에서는 최적 알고리즘 찾기가 쉬웠는데요. 좀 더 복잡한 문제에서는, 상계, 하계를 각각 구하기가, 특히 두 개가 매치되는 경우를 찾기가 힘들겁니다. 3-sum을 예로 들어 보겠습니다. 3-sum의 경우 브루트포스 알고리즘으로 나타내는 상계는 O(N^3)입니다. 그러나 우리는 더 나은 알고리즘을 찾았는데요. 러닝 타임이 O(N^2lnN)이였습니다. 더 좋은 상계를 주네요. 하계를 생각해보면, 일단 우리는 모든 엔트리를 검색해야합니다. 그렇지 않다면 3-sum이 0이되는 엔트리를 지나칠수있기때문이죠. 이로 인해 최적 알고리즘의 러닝 타임은 오메가(N)이 됩니다. 그러나 누구도 이보다 높은 하계를 찾지는 못했습니다. 그로인해 상계와 하계에 갭이 있게되고, 열린 문제로 남아있습니다. 3-sum 문제에 최적 알고리즘이 있나요? 우리는 모릅니다. 심지어 러닝 타임이 O(N^2)보다 작은 알고리즘이 있을지, 혹은 O(N)보다 높은 하계를 찾을 수 있는지 모릅니다. 이것이 알고리즘 이론 에서 열린 문제의 예시가 되겠네요. 3-sum 문제 풀이가 얼마나 어려운지 조차 모릅니다. 이런 접근법은 최근 수십년간 무척 성공적이였습니다. 새 문제를 찾고, 몇몇 알고리즘을 발견해서, 하계를 증명했습니다. 만약 상하계에 갭이 있다면, 상계를 낮출 알고리즘을 찾거나 하계를 높일 방법을 찾습니다. 보통 비자명한 하계를 찾기란 어렵습니다. 예를들어 모든 엔트리를 검색하는 것과 같은 자명한 하계는 쉽습니다만, 전에 다뤘던 유니언-파인트 문제와 같은 비장명한 하계에 대한 증명은 훨씬 더 어렵습니다. 그리고 지난 수십년간, 문제의 계산복잡도에 대해 많이 알게됐는데요 지속적으로 상계를 낮춰가면서 알고리즘이 최악의 케이스에 더 좋은 러닝타임을 가지도록 만들면서 말입니다. 여전히 갭이 남아있는 알고리즘이 많이 있습니다. 이 분야는 많은 사람들이 참여하는 매력적인 분야입니다. 이 과목의 맥락에서 볼때, 몇 가지 주의사항이 있습니다. 첫째는, 최악의 케이스에 집중하는건 어찌보면 조금 비관적일 수 있습니다. 현실의 문제들은 덜 비관적일지 모릅니다. 많은 공학 과학 분야에서는 최악의 케이스를 다루지 않습니다. 이 과목의 최악의 케이스는 번개가 내려쳐서 그냥 다 끝나버리는거겠죠. 가능성이 무척 낮습니다. 마찬가지로 알고리즘의 경우도 마찬가집니다. 아마도 우리는 인풋의 성질을 파악하는데 주력해서 그 성질에 맞는 최적의 알고리즘을 찾아야 할겁니다. 또 다른 점은 성능을 예상하고 알고리즘간 비교를 위해서는 우리는 '상수곱 내에서'보다 조금 더 가까이 볼 필요가있습니다. 알고리즘 이론에서 사용하는 빅 세타, 빅 오, 빅 오메가에서 틸드 표기법을 얘기했습니다. 알고리즘이론에는 무척 많은 연구결과가 있는데요, 많은 사람들은 빅 오 결과를, 러닝 타임의 근사 모델로써 문제 복잡도에서 향상된 상계를 주는걸로 해석하는 실수를 합니다. 이번 강의에서는, 틸드 표기법을 사용하면서 근사 모델에 집중할겁니다. 관심있는 특정한 수량에 특정한 결과를 갇도록, 러닝타임에 있어 상수, 특정되지 않은 상수는 시스템 상의 머신의 성질과 관련이있어야합니다. 이런 결과를 사용해서, 성능을 예상하고 알고리즘을 비교할 겁니다.