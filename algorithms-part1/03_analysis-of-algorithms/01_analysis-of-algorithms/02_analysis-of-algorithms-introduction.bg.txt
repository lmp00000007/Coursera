Добре дошли отново. Днес ще се занимаваме с малко математика и малко наука. Не много, но ще имаме нужда от научна основа за да разберем  производителността на нашите алгоритми, за да ги прилагаме правилно в практиката. Така че днес ще говорим за това, как да наблюдаваме показателите на производителността на алгоритмите. Ще разгледаме как се правят математически модели и как да класифицираме алгоритми според степента на нарастване на тяхното време за изпълнение. Ще говорим малко за теорията на алгоритмите и също как да анализираме употребата на паметта. За да погледнем от тази гледна точка, ще поразсъждаваме относно тези проблеми от гледна точка на различни типове персонажи. Първият е програмистът, който трябва да реши дадена задача и да накара решението да работи. Вторият е клиентът, който иска да използва програмата за да си свърши работата. Третият е теоретикът, това е някой, който горещо иска да разбере какво се случва. И, и последният тип е нещо като съвкупност - онова базово блокиране и боричкане, понякога необходимо за да станат нещата готови. Така че има по малко от всеки от тези типажи в днешната лекция. И всъщност като студенти, вие трябва да имате предвид, че един ден може да попаднете в една от тези роли, или във всички наведнъж. Затова е много важно да се разберат различните гледни точки. Ключът върху който ще се фокусираме е 'времето за изпълнение'. Всъщност идеята за анализа на времето за изпълнение на дадена сметка датира още от времето на Бабидж (Babbage) и вероятно преди него. И ето един цитат от Бабидж - "Щом се появи аналитична машина, тя задължително ще поведе бъдещото развитие на науката. Когато се потърсят резултати от помощта й, ще се появи въпросът 'с каква последователност от изчисления могат тези резултати да бъдат получени от машината за най-кратко време'". Ако погледнете машината на Бабидж наречена 'аналитичната машина', ще видите, че има ръчка на нея. И буквално проблемът, който Бабидж е имал бил колко пъти трябва да се дръпне ръчката на машината. Не е, не е много по-различно и в съвременния свят. Ръчката може да е нещо електронно, което се случва милиард пъти в секунда. Но ние отново се интересуваме колко пъти дадена дискретна (изброима) операция трябва да бъде приложена за да направим някакво изчисление. Така че в крайна сметка имаме много причини за да анализираме алгоритми. В контекста на този курс, ние се интересуваме основно от предсказването на производителността. Също искаме да сравняваме производителността на различни алгоритми за една и съща задача и да може да предоставим някои гаранции за това колко добре се представят. Заедно с това и да разберем някои теоретични основи за това как се представят алгоритмите. Но основната, практическата причина, поради която искаме да анализираме алгоритми и да ги разбираме е да избегнем бъгове заради производителността. Бихме искали да имаме известна увереност, че нашите алгоритми ще завършат изпълнението си в рамките на времето, което, което предполагаме, че ще е необходимо. И е много, много често срещано явление в съвременната изчислителна инфраструктура, ситуацията в която клиентът получава слаба производителност заради това, че програмистът не е разбирал характеристиките на производителността на алгоритъма. И целта на днешната лекция е да се опитаме да избегнем това. Сега ще се фокусираме върху производителността и сравнението на алгоритмите от този курс. Има курсове в програмата по компютърна наука, които съдържат повече информация относно теоретичната основа на алгоритми и аз ще разкажа малко за това на по-късен етап. Но нашият фокус е върху това да успеем да предсказваме производителността и да сравняваме алгоритми. Има дълъг списък от успешни примери за дизайн на алгоритъм с по-добра производителност, давайки решение на задачи, които иначе биха били нерешими. Ще дам няколко примера. Един от първите и най-известни е тъй нареченият FFT алгоритъм. Това е алгоритъм за разбиването вълновата форма на N извадки от сигнал на периодични компоненти. И това е в основата на DVD-тата и JPEG компресията, както и на много други приложения. Има лесен начин това да се направи, който отнема време за изпълнение пропорционално на N^2. Но FFT алгоритъмът отнема само N log N стъпки. И разликата между N log N и N^2 е, е разликата между това да можеш да решиш тежка задача и да не можеш да я решиш. Много от цифровите технологии, цифровите медии които имаме в наши дни, са имплементирани с този бърз алгоритъм. Друг пример беше реално разработен от Андрю Апел (Andrew Appel), който сега ръководи катедрата по компютърна наука тук в Принстън. И го беше разработил докато беше студент като дипломна работа. Това е бърз алгоритъм решаващ задачата за "N body simulation". Лесният алгоритъм отнема време пропорционално на N^2, но алгоритъмът на Апел отнемаше N log N което означаваше, че учените могат да правят "N body simulation" за големи стойности на N. И това предизвиква нови проучвания. Така че предизвикателството, с което обикновено се сблъскваме е, ще може ли моята програма да обработи голям, практически полезен вход? И, и всъщност, работещият програмист е изправен пред този проблем през цялото време. Защо, защо програмата ми работи толкова бавно? Защо й свършва паметта? И това е занимавало програмистите наистина дълго време, като  прозрението как може да се реши този проблем... Дойтер Кануф (Deuter Kanoof) през 1970-те години, открил, че наистина може да се ползва научният подход за да се разбере производителността на алгоритмите в действие. Може би не отключваме нови тайни на вселената, но ние можем да използваме научният подход и да се отнасяме към компютъра като нещо, което може да бъде изучавано по този начин и така да разберем каква ще бъде производителността на нашата програма. Нека да разгледаме това по-детайлно. Та това е просто кратко резюме на това какво разбираме като ползваме понятието "научен подход", ползван успешно в продължение на няколко века. Така че, това което ще направим, е да наблюдаваме някоя характеристика на естественият свят. В този случай това ще бъде времето за изпълнение на нашата програма на компютър. После ще изработим хипотеза някакъв модел, който се доближава до направените наблюдения, а след това ще се надяваме че, че хипотезата е достатъчно добра за да ни даде възможност да предскажем нещо. Обикновено да предскажем времето за изпълнение на по-тежка задача или на различен компютър. И след това ще проверим дали предсказването е било вярно, като направим още наблюдения и валидираме докато моделът и наблюденията не съвпаднат достатъчно задоволително. Това е начин да се сдобием със самочувствието, че разбираме производителността на нашите програми. Сега, в научния подход, има някои основни принципи и първият е, че ако ще правиш експерименти, трябва да очакваш, че някой друг също ще може да ги изпълни и да получи същите резултати. И също така хипотезите трябва да притежават специфична характеристика, така че чрез експериментите да се покаже дали хипотезата е вярна или не. Затова трябва да е внимателно изработена и ние ще се опитаме да направим точно това. Така че, отново, бъдещето на естествения свят, който изучаваме е някой конкретен компютър, който съществува в естествения свят. Това променя алгоритъма от абстракция, в нещо, в нещо като истинско материално нещо което се случва, като надбягващи се електрони в компютър.