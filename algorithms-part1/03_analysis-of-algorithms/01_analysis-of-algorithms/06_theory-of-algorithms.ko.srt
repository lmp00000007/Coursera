1
00:00:01,087 --> 00:00:07,024
증가기준분석은 너무 중요한 주제라서

2
00:00:07,024 --> 00:00:13,038
최근에 많은 연구들이 쏟아지고 있는데요, 잠깐 얘기해 보겠습니다.

3
00:00:13,038 --> 00:00:19,692
저번 강의해서 얘기했던 것보다 조금 더 복잡한 면이 있습니다

4
00:00:19,692 --> 00:00:25,747
첫째로는, 인풋에 따라 알고리즘의 성능 차이가 날 수 있습니다.

5
00:00:25,747 --> 00:00:31,076
그래서 인풋 종류에 따라서 알고리즘을 분석하는 다양한 방법을 생각해 볼 수 있습니다.

6
00:00:31,076 --> 00:00:37,001
러닝 타임은 최선의 케이스와 

7
00:00:37,001 --> 00:00:42,014
최악의 케이스 사이에 있을 겁니다. 최선의 케이스는 하계가됩니다.

8
00:00:42,014 --> 00:00:48,008
하계는 러닝 타임이 항상 그 이상일 것이라는것을 보장해주며,

9
00:00:48,008 --> 00:00:53,368
최악의 케이스는

10
00:00:53,368 --> 00:00:58,562
가장 어려운 인풋인데요, 분석하는데 걸리는 러닝 타임이 항상 이 상계보다는

11
00:00:58,562 --> 00:01:04,327
작다는걸 보장합니다. 그리고 많은 상황에서는

12
00:01:04,327 --> 00:01:11,078
인풋이 랜덤이라고 생각합니다. 현재 푸는 문제에 있어서

13
00:01:11,078 --> 00:01:17,577
랜덤이란 무슨뜻인지 정의할 모델이 필요한데요, 이게 가능한

14
00:01:17,577 --> 00:01:24,680
상황이 많습니다, 그로인해 인풋의 분산이 높아도 퍼포먼스를 쉽게 예상할 수 있게해줍니다.

15
00:01:24,680 --> 00:01:33,369
3-sum을 예로들면, 이건 항상 같은데요.

16
00:01:33,617 --> 00:01:39,441
틸드 표기법을 쓰면, 알고리즘에 있어 유일한 변이는, 

17
00:01:39,441 --> 00:01:46,514
카운터가 증가하는 횟수입니다. 그건 낮은 차 항이라서 우리 분석에서는

18
00:01:46,514 --> 00:01:53,318
신경쓸 필요가 없습니다. 바이너리 서치에 있어서, 바로

19
00:01:53,318 --> 00:02:00,553
발견하셨다시피 최선의 케이스는 상수 시간이 걸리고, 평균과 최악의

20
00:02:00,553 --> 00:02:08,205
케이스는 둘다 lnN입니다. 변동성이 높은 다른 경우 또한

21
00:02:08,205 --> 00:02:17,256
있습니다. 인풋에 따른 다른 분석 방법이 있는데요.

22
00:02:17,256 --> 00:02:22,398
실제 클라이언트가 풀려는 실제 문제에는 어떨까요?

23
00:02:22,398 --> 00:02:28,543
알고리즘의 성능을 이해하기 위해서는 이 부분도

24
00:02:28,543 --> 00:02:33,933
알아야 합니다. 성공적인 두 가지 접근법이 있습니다.

25
00:02:33,933 --> 00:02:40,346
하나는 최악의 케이스를 염두해 둔 디자인입니다. 이로인해 알고리즘이

26
00:02:40,346 --> 00:02:45,403
어느 상황에서도 빠른 성능을 보장합니다. 둘째는

27
00:02:45,403 --> 00:02:50,794
랜덤화해서 어떤 확률적 보장에 의존하는 겁니다 

28
00:02:50,794 --> 00:02:55,769
강의를 진행하면서 두 경우를 모두 볼겁니다.

29
00:02:55,769 --> 00:03:00,546
이런 증가도에 대한

30
00:03:00,546 --> 00:03:06,058
고려들을, 저는 

31
00:03:06,058 --> 00:03:12,022
알고리즘 이론이라고 부릅니다. 3-sum과 같이 풀어야할 문제가 있을때

32
00:03:12,022 --> 00:03:17,500
그게 얼마나 어려운지 알고 싶은게 이론의 목적입니다.

33
00:03:17,500 --> 00:03:24,302
문제에 대한 최고의 알고리즘을 알고 싶습니다. 컴퓨터 공학자들이

34
00:03:24,302 --> 00:03:30,091
여기에 쓰는 접근법으로는, 분석에 있어 세부사항을 최대한 억제하는겁니다.

35
00:03:30,091 --> 00:03:37,015
그로인해 상수 계수만 가지고 러닝 타임을 분석합니다. 이것이 증가도분석의 목적입니다.

36
00:03:37,015 --> 00:03:42,831
저는 또한 인풋 모델에 좌우되고 싶지도 않습니다.

37
00:03:42,831 --> 00:03:48,070
그래서 최악 케이스을 염두한 설계에 집중합니다.

38
00:03:48,090 --> 00:03:54,372
그 뒤에 단지 증가도만으로 알고리즘 성능을 설명할 수 있습니다. 사실

39
00:03:54,372 --> 00:03:59,357
문제 풀이의 복잡성에 대해 알려주는 매우 엄격한 방식으로 

40
00:03:59,357 --> 00:04:04,692
가능합니다. 우리의 목적은

41
00:04:04,692 --> 00:04:11,326
최악의 케이스를 발견함으로써 어떤 인풋에도 상수 계수안에서 특정 성능을 보장하는

42
00:04:11,326 --> 00:04:17,735
최적의 알고리즘을 찾는것인데요. 또한 

43
00:04:17,735 --> 00:04:24,022
어떤 알고리즘 보다도 최적인 알고리즘을 찾고 싶습니다. 추후에 몇가지

44
00:04:24,022 --> 00:04:31,549
예를 들겠습니다. 이런 분석을 위해 통상적으로 사용하는 표기법이 있는데요

45
00:04:31,549 --> 00:04:39,745
빅 세타, 빅 오, 빅 오메가 표기법입니다. 

46
00:04:40,033 --> 00:04:47,396
여기 표기법이 있습니다. 빅 세타 표기법은 증가도를

47
00:04:47,396 --> 00:04:53,733
표현합니다. 세타(N^2)는 N^2와 관련된 모든것을 나타냅니다.

48
00:04:53,733 --> 00:05:00,393
상하계 모두 N^2형으로 이루어져있고, 그게 우리가 알고리즘을 분류할때 사용하는 겁니다.

49
00:05:00,393 --> 00:05:05,730
빅 오 표기법은, 퍼포먼스의 상계를 나타냅니다

50
00:05:05,730 --> 00:05:11,360
빅 오(N^2)가 나타내는 것은, N이 증가할때 임의의 상수 곱하기 N^2보다는

51
00:05:11,360 --> 00:05:17,569
낮다는 겁니다. 빅 오메가는 하계를 의미하는데, N이 증가할때 N^2보다 크다는것을

52
00:05:17,569 --> 00:05:23,694
나타냅니다. 위 세가지 표기법은

53
00:05:23,918 --> 00:05:30,113
알고리즘 분류에 사용되는데, 추후에 보여드리겠습니다. 

54
00:05:30,113 --> 00:05:36,725
1,2,3-sum을 예로들면 쉽습니다.

55
00:05:36,725 --> 00:05:42,829
우리 목적은 문제의 어려움을 정립해보고, 최적의 알고리즘을 개발하는 겁니다.

56
00:05:42,829 --> 00:05:48,999
1-sum 문제는, 즉 배열에 0이 있나 찾는겁니다. 문제 난해성의 상계는 

57
00:05:48,999 --> 00:05:54,299
특정한 알고리즘으로 주어집니다. 예를 들면, 브루트포스(완전탐색)

58
00:05:54,299 --> 00:06:00,049
는 배열의 모든 엔트리를 모두 검색하는데요,

59
00:06:00,049 --> 00:06:06,490
다시말해 O(N)시간, 임의 상수 곱하기 N보다 작은 시간이 걸립니다.

60
00:06:06,490 --> 00:06:12,307
최적 알고리즘의 러닝 타임은 O(N)이 되어야하는데요,

61
00:06:12,307 --> 00:06:17,616
다시말하면, 이 특정 알고리즘은 최적 알고리즘의 러닝 타임의 상계를 줍니다.

62
00:06:17,616 --> 00:06:23,431
이 경우에는, 하계를 발견하기도 쉬운데요

63
00:06:23,431 --> 00:06:29,052
하계란, 어떤 알고리즘도 이보단 나을수 없다는걸 보여주죠. 1-sum에서는

64
00:06:29,052 --> 00:06:34,536
배열의 모든 엔트리를 검색해야합니다. 하나라도 놓친다면, 그 엔트리가

65
00:06:34,536 --> 00:06:40,016
0일지도 모르니까요. 다시말해, 최적의 알고리즘은 최소

66
00:06:40,016 --> 00:06:46,270
임의 상수 곱하기 N의 러닝 타임을 가져야합니다. 다시말해 빅 오메가(N)으로 표현하죠.

67
00:06:46,270 --> 00:06:52,287
이 경우에는, 상계와 하계가 같습니다. 그래서 상수곱 내에서는,

68
00:06:52,287 --> 00:06:59,133
브르투 포스 알고리즘이 1-sum에 있어 최적이라는걸 증명합니다.

69
00:06:59,133 --> 00:07:05,459
러닝 타임은 세타(N)이며, 오메가(N), O(N)과 같습니다.

70
00:07:05,459 --> 00:07:11,576
이런 쉬운 문제에서는 최적 알고리즘 찾기가 쉬웠는데요. 좀 더 복잡한 문제에서는,

71
00:07:11,576 --> 00:07:17,027
상계, 하계를 각각 구하기가, 특히 두 개가 매치되는 경우를 찾기가

72
00:07:17,027 --> 00:07:22,617
힘들겁니다. 3-sum을 예로 들어 보겠습니다.

73
00:07:22,617 --> 00:07:30,211
3-sum의 경우 브루트포스 알고리즘으로 나타내는 상계는 

74
00:07:30,211 --> 00:07:37,375
O(N^3)입니다. 그러나 우리는 더 나은

75
00:07:37,375 --> 00:07:43,691
알고리즘을 찾았는데요. 러닝 타임이 O(N^2lnN)이였습니다. 더 좋은 상계를 주네요.

76
00:07:43,691 --> 00:07:49,526
하계를 생각해보면, 일단 우리는 모든 엔트리를 검색해야합니다.

77
00:07:49,526 --> 00:07:56,274
그렇지 않다면 3-sum이 0이되는 엔트리를 지나칠수있기때문이죠. 이로 인해 최적 알고리즘의 러닝 타임은

78
00:07:56,274 --> 00:08:02,304
오메가(N)이 됩니다. 그러나 누구도 이보다 높은 하계를 찾지는 못했습니다.

79
00:08:02,304 --> 00:08:08,280
그로인해 상계와 하계에 갭이 있게되고,

80
00:08:08,280 --> 00:08:14,237
열린 문제로 남아있습니다. 3-sum 문제에 최적 알고리즘이 있나요? 우리는 모릅니다.

81
00:08:14,237 --> 00:08:20,592
심지어 러닝 타임이 O(N^2)보다 작은 알고리즘이 있을지, 혹은 

82
00:08:20,592 --> 00:08:27,130
O(N)보다 높은 하계를 찾을 수 있는지 모릅니다. 이것이 알고리즘 이론

83
00:08:27,130 --> 00:08:33,181
에서 열린 문제의 예시가 되겠네요. 3-sum 문제 풀이가 얼마나 어려운지 조차 모릅니다.

84
00:08:33,181 --> 00:08:40,448
이런 접근법은 최근 수십년간 무척 성공적이였습니다.

85
00:08:40,448 --> 00:08:45,958
새 문제를 찾고, 몇몇 알고리즘을 발견해서, 하계를 증명했습니다.

86
00:08:45,958 --> 00:08:51,679
만약 상하계에 갭이 있다면, 상계를 낮출 알고리즘을 찾거나

87
00:08:51,679 --> 00:08:56,527
하계를 높일 방법을 찾습니다. 보통 

88
00:08:56,527 --> 00:09:02,164
비자명한 하계를 찾기란 어렵습니다. 예를들어 모든 엔트리를 검색하는 것과 같은 자명한 하계는 쉽습니다만,

89
00:09:02,164 --> 00:09:07,435
전에 다뤘던 유니언-파인트 문제와 같은 비장명한 하계에 대한 증명은

90
00:09:07,435 --> 00:09:13,251
훨씬 더 어렵습니다. 그리고

91
00:09:13,251 --> 00:09:20,081
지난 수십년간, 문제의 계산복잡도에 대해 많이 알게됐는데요

92
00:09:20,081 --> 00:09:26,124
지속적으로 상계를 낮춰가면서

93
00:09:26,124 --> 00:09:31,979
알고리즘이 최악의 케이스에 더 좋은 러닝타임을 가지도록 만들면서 말입니다.

94
00:09:31,979 --> 00:09:37,944
여전히 갭이 남아있는 알고리즘이 많이 있습니다. 이 분야는 많은 사람들이 참여하는

95
00:09:37,944 --> 00:09:43,617
매력적인 분야입니다. 이 과목의 맥락에서 볼때, 몇 가지

96
00:09:43,617 --> 00:09:48,770
주의사항이 있습니다. 첫째는,

97
00:09:48,770 --> 00:09:54,409
최악의 케이스에 집중하는건 어찌보면 조금 비관적일 수 있습니다.

98
00:09:54,409 --> 00:09:59,786
현실의 문제들은 덜 비관적일지 모릅니다. 많은

99
00:09:59,786 --> 00:10:05,194
공학 과학 분야에서는 최악의 케이스를 다루지 않습니다.

100
00:10:05,194 --> 00:10:10,708
이 과목의 최악의 케이스는 번개가 내려쳐서 그냥 다 끝나버리는거겠죠. 가능성이 무척 낮습니다. 마찬가지로

101
00:10:10,708 --> 00:10:16,301
알고리즘의 경우도 마찬가집니다. 아마도 우리는 인풋의 성질을 파악하는데 주력해서

102
00:10:16,301 --> 00:10:21,252
그 성질에 맞는 최적의 알고리즘을 찾아야 할겁니다. 또 다른 점은

103
00:10:21,252 --> 00:10:26,645
성능을 예상하고 알고리즘간 비교를 위해서는 우리는

104
00:10:26,645 --> 00:10:33,210
'상수곱 내에서'보다 조금 더 가까이 볼 필요가있습니다.

105
00:10:33,210 --> 00:10:39,719
알고리즘 이론에서 사용하는 빅 세타, 빅 오, 빅 오메가에서 틸드 표기법을 

106
00:10:39,719 --> 00:10:46,161
얘기했습니다. 알고리즘이론에는 무척 많은 연구결과가 있는데요,

107
00:10:46,161 --> 00:10:51,608
많은 사람들은 빅 오 결과를, 러닝 타임의 근사 모델로써 

108
00:10:51,608 --> 00:10:56,964
문제 복잡도에서 향상된 상계를 주는걸로

109
00:10:56,964 --> 00:11:02,179
해석하는 실수를 합니다.

110
00:11:02,179 --> 00:11:07,619
이번 강의에서는, 틸드 표기법을 사용하면서 근사 모델에 

111
00:11:07,619 --> 00:11:12,738
집중할겁니다. 관심있는 특정한 수량에 특정한 결과를 갇도록, 

112
00:11:12,738 --> 00:11:17,766
러닝타임에 있어 상수, 특정되지 않은 상수는

113
00:11:17,766 --> 00:11:22,271
시스템 상의 머신의 성질과 관련이있어야합니다.

114
00:11:22,271 --> 00:11:27,542
이런 결과를 사용해서, 성능을 예상하고 알고리즘을

115
00:11:27,542 --> 00:11:29,013
비교할 겁니다.