다행히도, 알고리즘을 분석할 때
 (성능에 관한) 함수들이 그리 다양하지 않아서,
 알고리즘의 분류가 가능한데 구체적으로 '문제의 크기 증가(growth)에 따른
 성능'을 기준으로 분류할 수 있습니다. 이 것이 다음에 살펴볼 주제입니다.
 좋은 소식은 우리가 관심 갖는 알고리즘들에선 정말로 함수가 몇 개 등장하지 않는다는 점입니다. 물론 다른 함수를 갖도록 만들 수야 있겠고,
 즉, 이 좋은 소식에 대한 반례를 찾을 수 있겠지만 우리가 고려하는 대다수의 알고리즘은
 여기 그래프에 보이는 것과 같은 몇 개의 함수 뿐입니다. 그리고,
 함수의 증가도(the order of growth)를 논할 때에는, (최고차항의) 상수계수는 고려하지
 않습니다. 예를 들어 우리는 알고리즘의 실행 시간은
 N log N에 비례한다고 말할 수 있는데, 이는 '실행 시간이 C * log N, 아 아니,
 C * N log N에 근사(tilde)한다'라는 가설을 상정한 것으로, 여기서 C는 어떤 상수입니다. 그리고 이 그래프에서,
 이 그래프는 log-log 그래프라서, 증가도에 대한 아이디어를 잘 전달하지 못함을 감안하세요.
 예를 들어 증가도가 로그 함수이거나 상수 함수이면 그 실제 값이 얼마나 큰지는 중요치 않습니다.
 이 경우엔 실행 시간이 충분히 빠른 거죠. 예를 들어 문제의 크기가 1,000(1K)일 때 실행 시간이 T이면
 문제의 크기가 500,000(500K)이어도 T에 충분히 가깝습니다. 만약 선형 함수였다면,
 즉 증가도가 N에 비례한다면, 실행 시간은, 문제 크기가 증가할 때,
 그 크기에 대응하여 증가합니다. N log N일 때에도 이는 거의 같다고 볼 수 있습니다.
 이런 결과가 나오는 경우는 우리가 분투해 만든 알고리즘입니다. 입력 크기에 따라 증가하고,
 입력이 커지면 실행 시간도 커집니다. 이는 (우리가 만든 알고리즘이) 그렇게 되길 바랄만한,
 괜찮은 상황입니다. 앞에서 말했듯, 즉 Union-find에 대해 말했듯, 증가도가
 이차함수(quadratic)이면, 실행 시간은 입력 크기의 증가보다 훨씬 빠르게 증가합니다.
 큰 입력이 주어지면 그런 알고리즘의 사용은 가능하지 않죠. 삼차함수(qubic)이면 더 나쁩니다.
 따라서 많은 알고리즘에서 우리가 찾으려는 건 즉 가장 먼저 해볼 일은 그 증가도가
 이차함수나 삼차함수가 아님을 확인하는 겁니다. 이러한 증가도 기반의 분류는
 우리가 작성하는 코드의 단순한 패턴으로부터 옵니다.
 for 루프가 없는 코드라면, 증가도는 상수가 되겠죠.
 코드가 루프를 한 번 돌 때마다 입력을 절반으로 줄인다면,
 이항검색(binary search) 알고리즘 같은 것이 예가 될 수 있겠는데, 그 증가도는 분석을 해보면
 로그함수가 될 것이고 입력 크기를 두 배 증가해 실행 시간을 비교하는 검사를 해보면,
 매우 큰 입력에 대해 거의 선형적으로 증가할텐데 즉 입력 크기를 두 배 해보면, 아 미안합니다, 선형적이 아니라 상수 함수처럼 어떤 상수가 될 겁니다.
 Log N을 볼 일이 거의 없겠지만요. 입력을 모두 다루어야 하는 루프가
 하나 있다면, 그 실행 시간은 선형 함수이고, N에 비례할 겁니다.
 그런 함수의 예시로 배열에서 0의 개수를 세거나 최댓값을 찾는 알고리즘을 들 수 있습니다.
 1-합 문제같이요. 매우 흥미로운 카테고리로 N log N 알고리즘,
 또는 linearthmic이라 불리는 증가도 함수가 있습니다. 이 함수는 특별한 종류의 알고리즘
 설계 기법에서 등장하곤 하는데, 그 기법의 이름은 분할 정복(divide-and-conquer)입니다.
 합병 정렬(Mergesort) 알고리즘을 2주 안에 다룰텐데, 분할 정복의 대표적 사례입니다. 그리고 2-합 알고리즘처럼 두 개의 for 루프를 가지면,
 증가도는 보통 N^2에 비례하게 됩니다. 볼 수 있듯이, 이차식이죠. 3-sum 알고리즘 처럼 세 개의 for loop가 있는 경우가 있는데, N^3, 즉 세제곱 형태가 될 겁니다. 이차식 혹은 삼차식 알고리즘의 경우 입력이 두 배 증가할때 러닝타임은, 이차식의 경우 4배 삼차식의 경우 8배 증가합니다. 프로그램이 끝나기를 하염없이 기다리면서 머릿속으로 계산해 볼 수 있겠죠. 러닝타임이 지수함수적인 알고리즘이 있습니다. 이 경우에 N이 매우 커지지는 않는데, 강의 후반 두개의 강의에서 보겠습니다. 증가도의 실질적 함의를 보겠습니다. 나중에 정말 흥미로운 알고리즘을 다룰때 다시 돌아와 살펴보는것을 제외하고는 너무 깊게 들어가지는 않을겁니다. 규모가 큰 문제를 다룰 수 있는 선형,로그함수적 알고리즘을 말합니다. 왜냐하면 현재 컴퓨터로도 이차식의 경우 수만개의 입력 규모, 삼차식의 경우 수천개의 입력 규모뿐밖에 다루지 못합니다. 이삼차식 알고리즘이 잘 쓰이지 않는 이유로는, 현재 다루는 데이터 규모는 보통 수백만에서 수십억개 혹은 그 이상이기때문입니다. 과거에는 이 알고리즘의 실용성에 대한 논의가 있었지만 시간이 지남에 따라 실용적이지 않다고 결론을 내렸고, 그로인해 더 나은 알고리즘이 필요합니다. 알고리즘의 퍼포먼스를 설명해줄 수학적 모델을 개발하는 절차를 보여주기 위해서 친숙한 바이너리 서치 알고리즘을 보겠습니다. 정렬된 정수형 배열이 있을때, 키가 주어지고, 키가 배열에 있는지 있다면 인덱스를 알고싶은 상황입니다. 이 작업에는 바이너리 서치 알고리즘이 빠른데요, 일단 주어진 키를 배열의 중간 엔트리와 비교합니다. 이 케이스에서는 주어진 키 33을, 미들 엔트리 53과 비교합니다. 만약 주어진 키 값이 더 작다면 배열 왼쪽에 있고, 크다면 배열 오른쪽에 있으며, 만약 값이 같다면 서치 목표 달성이라는걸 알고있습니다. 그리고나서 이걸 재귀적으로 적용합니다. 간단히 데모를 보시죠. 배열에서 33을 찾고 있습니다. 배열의 중간 엔트리인 53과 비교합니다. 33이 더 작으니깐 왼쪽으로 갑니다. 이제부터는 53 왼쪽부분만 보는겁니다. 왼쪽 중간인 25와 비교합니다. 33이 더 크기때문에 오른쪽으로 갑니다. 왼쪽 절반 중 다시 오른쪽 절반에만 관심이 있습니다. 갈수록 더 적은 하위 배열만 보죠. 중간은 43이고, 33이 더 작으므로 왼쪽으로 갑니다. 이제 살펴볼 서브 어레이는에는 엔트리가 한 개 밖에 없는데, 비교해보니 키 값과 같네요. 그러니 인덱스 4를 반환합니다. 만약 배열에 없는 걸 찾고있다면 일단 과정은 같습니다. 34를 찾고있는데요, 왼쪽 절반을 보고, 다시 그 오른쪽 절반을 보고 43 왼편에는 비교할 값이 한개 뿐이 없는데요. 34가 아니기 때문에, 여기 배열에는 찾는 키값이 없다는것을 알 수 있습니다. 이게 바이너리 서치입니다. 여기 바이너리 서치 코드가 있습니다. 실제로 바이너리 서치는 간단한 알고리즘임에도 불구하고 모든 세부사항을 정확히 하기가 어렵다고 정평이 나있습니다. 실제로, 한 논문에서는 처음으로 버그가 없는 바이너리 서치는 1962년에야 출간됬다고 주장합니다. 심지어 2006년에 자바 바이너리 서치 구현에서 버그가 발견되었는데요 알고리즘 개발에 있어서 얼마나 주의해야하는지 보여줍니다. 특히 수백만명이 사용하는 라이브러리의 경우에는 더 그렇습니다. 여기 구현이 있습니다. 종종 재귀적으로 구현하긴 하지만, 지금 경우에는 아닙니다. 제가 말로 설명한것을 그대로 반영하는 코드입니다. 키가 배열에 있는지 알려고 두 개의 포인터를 씁니다, lo, hi를 통해 관심있는 서브 어레이에서 lo가 hi보다 작거나 같으면 미들을 계산합니다. 그 뒤 주어진 키를 미들과 비교해서 실제로 비교는 세 가지 경우를 보는데요. 작은지 ,큰지, 같은지 같다면 미들 인덱스를 반환합니다. 작다면, hi 포인터를 재조정하고, 만약 크다면, lo 포인터를 재조정합니다. 포인터가 같은 값을 가질때까지 수행합니다. 만약 lo=hi가 같은데, 그 값이 주어진 키 값과 같지 않다면 -1을 반환합니다. 이 부등식을 생각해보면, 이 프로그램이 작동할것이라고 자신할 수 있을겁니다. 키가 배열에 있다면, lo와 hi 사이에 있을겁니다. 여러분에게 친숙한 프로그램이였습니다. 이제 수학적 분석을 해봅시다. 이 정리는 증명하기에 쉽습니다. 많은 정리 증명을 하진 않을텐데요, 이것은 쉽습니다. 바이너리 서치는 정렬된 사이즈 N 배열에서, 최대 1+lnN만큼의 비교를 한다는 겁니다. 그럼 일단 변수 T(N)을 사이즈 N 바이너리 서치에 필요한 비교 횟수라고 정의하면서 시작합니다. 코드를 반영해주는 재귀식을 써보겠습니다. 코드는 문제 규모를 절반으로 나눕니다. 그래서 만약에 T(N)이 T(N/2) +1보다 작거나 같다면, 비교를 어떻게 카운트하느냐에 따라서 다르지만, two-way 비교라고 한다면, 한 번 비교를 함으로써 N이 1보다 큰 한, 위에 식은 성립합니다. 만약 N이 1이라면, 답은 1이겠죠. 계산 과정을 나타내는 재귀식을 봤습니다. 첫번째 항에 재귀식을 반복적으로 적용함으로써, 위 식을 풀 수 있는데요, 이 기법을 텔레스코핑이라고 합니다. T(N)에 대해 참이라면 T(N/2)에도 적용할 수 있고 이런식으로 계속 적용해서 T(1)이 될때까지 하는데, 그렇게 되면 값은 1+lnN이 됩니다. 이게 N이 2의 제곱일때만 성립하는게 아니냐고 생각할 수 있습니다. N이 홀수일때의 경우를 특정하지 않았기 때문에 그럴 수 있습니다. 그렇지만 이런 세부사항은 쉽게 관리할 수 있고 바이너리 서치의 러닝 타임은 항상 로그함수적이라는걸 보여줄 수 있습니다. 이 사실로 인해서, 우리는 더 빠른 3-sum 알고리즘을 만들 수 있습니다. 정렬 기반 알고리즘인데요. 일단 인풋으로 주어진 숫자들을 정렬할겁니다. 정렬 알고리즘은 다음 주에 다룰겁니다. NlnN에 비례하는 시간에 할 수 있지만, 그게 계산의 주요 부분은 아닙니다. 주요 부분은 숫자가 정렬된 후에, 각 숫자의 순서쌍 a[i], a[j]마다 -(a[i]+a[j])에 대해 바이너리 서치를 할 겁니다. 만약 그 값을 찾는다면, 위 세 값의 합이 0이 되는겁니다. 숫자를 정렬한후에, 각 순서쌍마다 바이너리 서치를 해서 -(-40+0)은 40이고 바이너리 서치를 해보면, 배열에 값이 있으니깐 3-sum 문제의 해를 하나 찾았네요. 이걸 모든 순서쌍에 하는 겁니다. 분석을 보면, 러닝타임의 증가도는 N^2lnN이라고 나오네요. 좋은 정렬 알고리즘을 사용할 필요도 없습니다. 가장 처음 다룬 기본적인 삽입 정렬을 쓸 수 있습니다. 각 N^2개의 순서쌍마다 바이너리 서치를 하는데 드는 시간은 N^2lnN의 러닝 타임을 가집니다. 퍼포먼스 개선에 대한 간단한 예를 볼 수 있습니다. 문제를 푸는데 개선된 알고리즘을 찾을 수 있었습니다. N^2lnN은 N^3보다 훨씬 적은 시간이 걸립니다. 만약 정렬을 한후, 바이너리 서치를 하는 위 과정을 한다면, 프로그램 속도가 더 빠를겁니다. 실제 해보면, 전에는 N이 8000이였을때 51초 걸렸던 것이 지금은 1초가 채 걸리지 않습니다. 지금은 50초로 64000 규모를 풀 수 있습니다. 보통  알고리즘의 증가도가 더 좋다는것을 실 상황에서의 빠름으로 기대합니다. 실제 알고리즘 세부사항을 검사하는데 있어서는 실제 테스트해도보고 어떤게 더 빠른지 볼 수 있습니다. 분명히 N^3와 비교해보면 N^2lnN을 비교해보면, 우리가 더 좋은 알고리즘을 가졌다는걸 기대할 수 있습니다.