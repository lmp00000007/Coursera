De hecho el orden de crecimiento en las clasificaciones son tan importantes que han llevado a enormes cantidades de investigación en años recientes y hablaremos brevemente de eso ahora. Entonces, la vida es un poco más complicada que lo señalado en el último ejemplo y un problema es que los "inputs" (las entradas) pueden hacer que la performance (el desempeño) del algoritmo varíe ampliamente. Entonces a menudo tenemos que pensar acerca de diferentes maneras de analizar el algoritmo dependiendo del "input". Entonces, el tiempo de proceso va a estar en algún lugar entre el mejor caso y el peor caso. El mejor caso es el límite inferior en cuanto a costo. Asegura que el tiempo de proceso va a ser siempre mayor que eso, o no menor que eso, y luego está el peor caso que es el de más difícil "input". Si analizamos que entonces podemos garantizar que el tiempo de proceso en el algoritmo no será mayor que ese. Y luego en un montón de situaciones podríamos considerar que nuestro "input" sea aleatorio. Bien, vamos a necesitar de algún modo modelar lo que queremos significar por aleatorio para el problema que estamos resolviendo pero hay un montón de situaciones en las que podemos hacer eso y luego tenemos una manera para predecir el desempeño aún cuando el "input" pudiera variar ampliamente. Así por ejemplo para 3-sum, es más o menos siempre lo mismo. Con la notación de tilde, la única variabilidad en ese algoritmo es la cantidad de veces que el contador es incrementado y eso está en términos de bajo orden así que esto no va a estropear nuestro análisis. Para búsquedas binarias es, podrían encontrar enseguida en cuyo caso es tiempo constante y podemos demostrar que el caso promedio y el peor son ambos logaritmos base 2 de (N). Hay otros ejemplos en los que hay mucha más variabilidad aún. Entonces, tenemos estos diferentes tipos de análisis dependiendo del "input'. Pero la pregunta es: ¿qué pasa con el problema real que el cliente está tratando de resolver? Entonces tenemos que entender esos dos para poder entender el desempeño del algoritmo. Y hay dos aproximaciones que son exitosas en esto. Una es diseñar para el peor caso, sólo para asegurarnos que el algoritmo siempre corra rápido y esa es definitivamente ideal. Otra es si no pueden hacer eso, es aleatorizar y luego depender de alguna clase de garantía probabilística, y veremos ejemplos de ambas a medida que avanzamos en el curso. Ahora, esa clase de consideraciones, saben, la idea de orden de crecimiento, lleva a la discusión de lo que se llama, lo que yo llamo teoría de los algoritmos. Y aquí nuestros objetivos son, tenemos un problema a resolver, como resolver el problema de suma-3 y queremos saber cuán difícil es. Queremos encontrar el mejor algoritmo para resolver ese problema. La aproximación que el científico en computación usa para esto es tratar de suprimir del análisis tanto detalle como sea posible. Y así sólo analizar el tiempo de proceso o dentro de un factor constante. Eso es a lo que el orden de crecimiento está arribando, y también quiero no preocuparme por el modelo de "input". Y así nos enfocamos en un diseño para el peor caso y podemos hablar del desempeño de los algoritmos sólo en términos de orden de crecimiento y realmente es posible, es realmente posible hacer eso de un modo muy riguroso que nos enseña mucho sobre la dificultad de resolver problemas. Y nuestro objetivo es encontrar un algoritmo óptimo donde podemos garantizar dentro de un factor constante cierto desenpeño para cualquier "input" porque hemos cubierto el peor caso, pero también podemos haber aprobado que no se sabía que el algoritmo podía proveer una mejor garantía de desempeño. Voy a dar un par de ejempos fáciles de esto. Ahora, para hacer esto, están estas notaciones comunmente usadas llamadas Theta mayúscula, O mayúscula y Omega mayúscula. Entonces esas definiciones se dan acá. Entonces, la notación Theta mayúscula es sóo una forma de describir el orden de crecimiento. Theta(N)^2 es una especie de abreviatura para cualquier cosa N^2. Está limitada arriba y abajo por el tiempo constante N^2 y eso es lo que realmente usamos para clasificar algoritmos. Y luego, está la notación O mayúscula que es el límite superior de desempeño. Cuando decimos O(N^2), queremos decir que es menos que algun tiempo constante N^2 a medida que N crece. Y Omega mayúscula se usa para el límite inferior, significa mayor que algún tiempo constante N^2 a medida que N aumenta. Entonces esas tres notaciones podemos usarlas para clasificar algoritmos, y les voy a mostrar a continuación. Así, ejemplos de nuestros 1-sum, 2-sum y 3-sum son fácil de articular entonces nuestro objetivo es establecer la dificultad del problema y desarrollar un algoritmo óptimo. Así, el problema 1-sum es OO en el arreglo. Bien, un límite superior en la dificultad del problema es algún algoritmo específico. Entonces, por ejemplo, el algoritmo de fuerza bruta que miraba, que mira a cada elemento del arreglo es un algoritmo específico y significa eso, y eso toma un tiempo O(N). Tenemos que mirar a todos, es menos que un tiempo constante N para cierta constante. Entonces, el tiempo de proceso del algoritmo óptimo tiene que ser O(N) que es el límite superior para ese algoritmo específico del tiempo de proceso del algoritmo óptimo. Pero en este caso también es fácil desarrollar un límite inferior, que es una prueba de que ningún algoritmo puede hacerlo mejor. Bien, para 1-sum tienen que examinar todos los elementos en el arreglo. Si saltean alguno, entonces ese podría ser cero y eso significa que el algoritmo óptimo tiene que tener un tiempo de proceso por lo menos N por alguna constante donde decimos que el tiempo de proceso es Omega de N. Ahora, en este caso, el límite superior y el inferior coinciden. Entonces, haciendo el factor constante así, es una prueba de que el algoritmo de fuerza bruta para 1-sum es óptimo. Su tiempo de proceso es Theta(N). Es al mismo tiempo Omega y O(N). Eso es, para ese simpe problema estaba bien para obtener el algoritmo óptimo. Para problemas más complicados va a ser más difícil obtener el balance superior y el balance inferior, y particularmente un balance superior y un balance inferior que coincidan. Por ejemplo, miremos al 3-sum. Así, el balance superior para 3-sum, digamos nuestro primer algritmo de fuerza bruta, digamos que la prueba, fue una prueba en la que el tiempo de proceso del algoritmo óptimo es O(N^3) pero encontramos un mejor algoritmo, cuyo tiempo de proceso es O(N^2) lg N. Entonces, ese es un mejor límite superior. El límite inferior, bueno, tenemos que examinar todas las entradas porque otra vez, podríamos saltear alguna que haga 3-sum igual a cero y eso es una prueba de que el tiempo de proceso en el algoritmo óptimo es Omega(N) pero nadie conoce el límite superior o inferior para 3-sum. Entonces hay una brecha entre el límite superior y el inferior y es un problema abierto. ¿Hay un algoritmo óptimo para 3-sum? No sabemos cuál es. Ni siquiera sabemos si hay un algoritmo cuyo tiempo de proceso sea menor que O(N^2) ni sabemos si los límites superior e inferior son lineales.  Entonces ese es un ejemplo de un problema abierto en la teoría de algoritmos, no sabemos cuán difícil es resolver el problema 3-sum. Ahora, este punto de vista ha sido extremadamente exitoso en décadas recientes. Tenemos un problema nuevo, desarrollamos algún algoritmo, probamos el límite inferior. Si hay una brecha, buscamos un nuevo algoritmo que baje el límite superior o tratamos de encontrar una manera de elevar el límite inferior. Usualmente es muy difícil demostrar límites inferiores no triviales. Límites inferiores triviales, como mirar cada item de "input" no es tan difícil. Límites inferiores no triviales como por ejempo, la prueba que estuvimos hablando acerca del problema Union-Find son mucho más difíciles. Y en las últimas varias décadas la gente ha aprendido acerca de la dificultad computacional de los problemas examinando límites superiores que decrecen suavemente de modo que los algoritmos eran mejores peores casos de tiempo de proceso para cantidades y cantidades de problemas importantes y muchos algoritmos óptimos y muchas brechas aún permanecen. Es un campo de investigación fascinante en el cual mucha gente está involucrada. Ahora, hay un par de advertencias en el contexto de este curso. La primera es que podría ser demasiado pesimista enfocarse en el peor caso. Tenemos datos ahí afuera. Tenemos problemas que resolver. Quizás los datos no consitituyan el pero caso, y hay muchos campos de la ingeniería y la ciencia en los que no nos enfocamos en el peor caso. El peor caso para este curso sería que caiga un rayo y se termine y no tenemos un pan para eso. Y de la misma manera es verdad para los algoritmos.  Tal vez deberíamos enfocarnos en entender las propiedades de los "inputs" y encontrar algoritmos que sean eficientes para esos "inputs". Y la otra cosa es que para realmente predecir y comparar algoritmos necesitamos hacer un anáisis más detallado que lo que es dentro de un factor constante. Así que hablamos acerca de la notación con tilde en Theta mayúscula, O mayúscula y Omega mayúscula, que son usadas en la teoría de algoritmos. Y realmente hay tanta investigación publicada sobre la teoría de algoritmos que un montón de gente comete el error de interpretar que los resultados de la O mayúscula se supone que dan mejores límites superiores sobre la dificultad del problema como modelos aproximados del tiempo de proceso y eso es realmente un error. Entonces, en este curso, vamos a enfocarnos en aproximar modelos por medio de, saben asegurarnos que usamos la notación con tilde y trataremos de dar resultados específicos para ciertas cantidades de interés y la constante, cualquier constante no inespecífica en el tiempo de proceso tendrá que ver con propiedades de la máquina y del sistema, entonces serán capaces de utilizar estos resutados para predecir desempeño y para comparar algoritmos.