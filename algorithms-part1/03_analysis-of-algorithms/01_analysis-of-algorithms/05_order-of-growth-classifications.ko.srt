1
00:00:03,064 --> 00:00:08,071
다행히도, 알고리즘을 분석할 때
 (성능에 관한) 함수들이

2
00:00:08,071 --> 00:00:14,746
그리 다양하지 않아서,
 알고리즘의 분류가 가능한데

3
00:00:14,746 --> 00:00:20,978
구체적으로 '문제의 크기 증가(growth)에 따른
 성능'을 기준으로 분류할 수 있습니다.

4
00:00:20,978 --> 00:00:27,173
이 것이 다음에 살펴볼 주제입니다.
 좋은 소식은 우리가 관심 갖는 알고리즘들에선

5
00:00:27,173 --> 00:00:31,915
정말로 함수가 몇 개 등장하지 않는다는 점입니다.

6
00:00:31,915 --> 00:00:37,479
물론 다른 함수를 갖도록 만들 수야 있겠고,
 즉, 이 좋은 소식에 대한 반례를 찾을 수 있겠지만

7
00:00:37,479 --> 00:00:43,394
우리가 고려하는 대다수의 알고리즘은
 여기 그래프에 보이는 것과 같은

8
00:00:43,394 --> 00:00:50,362
몇 개의 함수 뿐입니다. 그리고,
 함수의 증가도(the order of growth)를 논할 때에는,

9
00:00:50,362 --> 00:00:55,793
(최고차항의) 상수계수는 고려하지
 않습니다. 예를 들어 우리는

10
00:00:55,793 --> 00:01:00,971
알고리즘의 실행 시간은
 N log N에 비례한다고 말할 수 있는데,

11
00:01:00,971 --> 00:01:06,686
이는 '실행 시간이 C * log N, 아 아니,
 C * N log N에 근사(tilde)한다'라는 가설을 상정한 것으로,

12
00:01:06,686 --> 00:01:12,671
여기서 C는 어떤 상수입니다. 그리고 이 그래프에서,
 이 그래프는 log-log 그래프라서, 증가도에 대한

13
00:01:12,671 --> 00:01:18,801
아이디어를 잘 전달하지 못함을 감안하세요.
 예를 들어 증가도가 로그 함수이거나 상수 함수이면

14
00:01:18,801 --> 00:01:25,026
그 실제 값이 얼마나 큰지는 중요치 않습니다.
 이 경우엔 실행 시간이 충분히 빠른 거죠.

15
00:01:25,026 --> 00:01:32,082
예를 들어 문제의 크기가 1,000(1K)일 때 실행 시간이 T이면
 문제의 크기가 500,000(500K)이어도 T에 충분히 가깝습니다.

16
00:01:32,082 --> 00:01:38,674
만약 선형 함수였다면,
 즉 증가도가 N에 비례한다면,

17
00:01:38,674 --> 00:01:44,945
실행 시간은, 문제 크기가 증가할 때,
 그 크기에 대응하여 증가합니다.

18
00:01:44,945 --> 00:01:51,031
N log N일 때에도 이는 거의 같다고 볼 수 있습니다.
 이런 결과가 나오는 경우는 우리가 분투해 만든 알고리즘입니다.

19
00:01:51,031 --> 00:01:56,755
입력 크기에 따라 증가하고,
 입력이 커지면 실행 시간도 커집니다.

20
00:01:56,755 --> 00:02:02,647
이는 (우리가 만든 알고리즘이) 그렇게 되길 바랄만한,
 괜찮은 상황입니다. 앞에서 말했듯,

21
00:02:02,647 --> 00:02:07,843
즉 Union-find에 대해 말했듯, 증가도가
 이차함수(quadratic)이면, 실행 시간은

22
00:02:07,843 --> 00:02:13,469
입력 크기의 증가보다 훨씬 빠르게 증가합니다.
 큰 입력이 주어지면 그런 알고리즘의 사용은 가능하지 않죠.

23
00:02:13,469 --> 00:02:21,397
삼차함수(qubic)이면 더 나쁩니다.
 따라서 많은 알고리즘에서 우리가 찾으려는 건

24
00:02:21,397 --> 00:02:28,515
즉 가장 먼저 해볼 일은 그 증가도가
 이차함수나 삼차함수가 아님을 확인하는 겁니다.

25
00:02:28,515 --> 00:02:35,708
이러한 증가도 기반의 분류는
 우리가 작성하는 코드의

26
00:02:35,708 --> 00:02:41,918
단순한 패턴으로부터 옵니다.
 for 루프가 없는 코드라면,

27
00:02:41,918 --> 00:02:49,033
증가도는 상수가 되겠죠.
 코드가 루프를 한 번 돌 때마다

28
00:02:49,033 --> 00:02:54,276
입력을 절반으로 줄인다면,
 이항검색(binary search) 알고리즘 같은 것이 예가 될 수 있겠는데,

29
00:02:54,276 --> 00:03:00,676
그 증가도는 분석을 해보면
 로그함수가 될 것이고

30
00:03:00,676 --> 00:03:06,879
입력 크기를 두 배 증가해 실행 시간을 비교하는 검사를 해보면,
 매우 큰 입력에 대해 거의 선형적으로 증가할텐데

31
00:03:06,879 --> 00:03:12,633
즉 입력 크기를 두 배 해보면, 아 미안합니다, 선형적이 아니라

32
00:03:12,633 --> 00:03:18,252
상수 함수처럼 어떤 상수가 될 겁니다.
 Log N을 볼 일이 거의 없겠지만요.

33
00:03:18,252 --> 00:03:25,070
입력을 모두 다루어야 하는 루프가
 하나 있다면, 그 실행 시간은

34
00:03:25,070 --> 00:03:31,592
선형 함수이고, N에 비례할 겁니다.
 그런 함수의 예시로 배열에서 0의 개수를

35
00:03:31,592 --> 00:03:38,205
세거나 최댓값을 찾는 알고리즘을 들 수 있습니다.
 1-합 문제같이요.

36
00:03:38,205 --> 00:03:44,681
매우 흥미로운 카테고리로 N log N 알고리즘,
 또는 linearthmic이라 불리는 증가도 함수가 있습니다.

37
00:03:44,681 --> 00:03:50,143
이 함수는 특별한 종류의 알고리즘
 설계 기법에서 등장하곤 하는데,

38
00:03:50,143 --> 00:03:55,573
그 기법의 이름은 분할 정복(divide-and-conquer)입니다.
 합병 정렬(Mergesort) 알고리즘을 2주 안에

39
00:03:55,573 --> 00:04:01,012
다룰텐데, 분할 정복의 대표적 사례입니다. 그리고

40
00:04:01,012 --> 00:04:07,543
2-합 알고리즘처럼 두 개의 for 루프를 가지면,
 증가도는 보통 N^2에 비례하게 됩니다.

41
00:04:07,543 --> 00:04:13,530
볼 수 있듯이, 이차식이죠. 3-sum 알고리즘 처럼 세 개의 for loop가 있는 경우가 있는데,

42
00:04:13,530 --> 00:04:19,369
N^3, 즉 세제곱 형태가 될 겁니다. 이차식 혹은 삼차식 알고리즘의 경우

43
00:04:19,369 --> 00:04:25,312
입력이 두 배 증가할때 러닝타임은, 이차식의 경우 4배

44
00:04:25,312 --> 00:04:30,331
삼차식의 경우 8배 증가합니다.

45
00:04:30,331 --> 00:04:35,952
프로그램이 끝나기를 하염없이 기다리면서 머릿속으로 계산해 볼 수 있겠죠.

46
00:04:35,952 --> 00:04:41,645
러닝타임이 지수함수적인 알고리즘이 있습니다.

47
00:04:41,645 --> 00:04:47,059
이 경우에 N이 매우 커지지는 않는데, 강의 후반 두개의 강의에서

48
00:04:47,059 --> 00:04:53,150
보겠습니다. 증가도의 실질적 함의를 보겠습니다.

49
00:04:53,150 --> 00:04:59,352
나중에 정말 흥미로운 알고리즘을 다룰때 다시 돌아와 살펴보는것을 제외하고는

50
00:04:59,352 --> 00:05:04,723
너무 깊게 들어가지는 않을겁니다. 

51
00:05:04,723 --> 00:05:11,633
규모가 큰 문제를 다룰 수 있는 선형,로그함수적 알고리즘을 말합니다. 왜냐하면 현재 컴퓨터로도

52
00:05:11,635 --> 00:05:17,913
이차식의 경우 수만개의 입력 규모, 삼차식의 경우

53
00:05:17,913 --> 00:05:23,246
수천개의 입력 규모뿐밖에 다루지 못합니다.

54
00:05:23,246 --> 00:05:28,567
이삼차식 알고리즘이 잘 쓰이지 않는 이유로는, 현재 다루는 데이터 규모는

55
00:05:28,567 --> 00:05:34,689
보통 수백만에서 수십억개 혹은 그 이상이기때문입니다.

56
00:05:34,689 --> 00:05:41,269
과거에는 이 알고리즘의 실용성에 대한 논의가 있었지만

57
00:05:41,269 --> 00:05:47,154
시간이 지남에 따라 실용적이지 않다고 결론을 내렸고, 그로인해 

58
00:05:47,154 --> 00:05:52,593
더 나은 알고리즘이 필요합니다. 알고리즘의 퍼포먼스를 설명해줄 수학적 모델을

59
00:05:52,593 --> 00:05:57,756
개발하는 절차를 보여주기 위해서 친숙한 바이너리 서치 알고리즘을 보겠습니다.

60
00:05:57,756 --> 00:06:03,037
정렬된 정수형 배열이 있을때,

61
00:06:03,037 --> 00:06:08,323
키가 주어지고, 키가 배열에 있는지

62
00:06:08,323 --> 00:06:13,321
있다면 인덱스를 알고싶은 상황입니다. 이 작업에는 바이너리 서치 알고리즘이 빠른데요, 

63
00:06:13,321 --> 00:06:18,178
일단 주어진 키를 배열의 중간 엔트리와 비교합니다.

64
00:06:18,178 --> 00:06:22,941
이 케이스에서는 주어진 키 33을, 미들 엔트리 53과 비교합니다.

65
00:06:22,941 --> 00:06:27,737
만약 주어진 키 값이 더 작다면 배열 왼쪽에 있고, 크다면 

66
00:06:27,737 --> 00:06:32,819
배열 오른쪽에 있으며, 만약 값이 같다면 서치 목표 달성이라는걸 알고있습니다. 그리고나서

67
00:06:32,819 --> 00:06:39,680
이걸 재귀적으로 적용합니다. 간단히 데모를 보시죠. 배열에서 33을 찾고 있습니다.

68
00:06:39,680 --> 00:06:45,777
배열의 중간 엔트리인 53과 비교합니다. 

69
00:06:45,777 --> 00:06:51,160
33이 더 작으니깐 왼쪽으로 갑니다. 이제부터는 53 왼쪽부분만 보는겁니다.

70
00:06:51,160 --> 00:06:56,788
왼쪽 중간인 25와 비교합니다. 33이 더 크기때문에 오른쪽으로 갑니다.

71
00:06:56,788 --> 00:07:02,399
왼쪽 절반 중 다시 오른쪽 절반에만 관심이 있습니다. 갈수록 더 적은 하위 배열만 보죠.

72
00:07:02,399 --> 00:07:08,690
중간은 43이고, 33이 더 작으므로 왼쪽으로 갑니다.

73
00:07:08,690 --> 00:07:15,019
이제 살펴볼 서브 어레이는에는 엔트리가 한 개 밖에 없는데, 비교해보니 키 값과 같네요. 그러니 인덱스 4를

74
00:07:15,019 --> 00:07:21,234
반환합니다. 만약 배열에 없는 걸 찾고있다면

75
00:07:21,234 --> 00:07:26,874
일단 과정은 같습니다. 34를 찾고있는데요, 왼쪽 절반을 보고, 다시 그 오른쪽 절반을 보고

76
00:07:26,874 --> 00:07:32,923
43 왼편에는 비교할 값이 한개 뿐이 없는데요.

77
00:07:32,923 --> 00:07:39,478
34가 아니기 때문에, 여기 배열에는 찾는 키값이 없다는것을 알 수 있습니다. 이게 바이너리 서치입니다.

78
00:07:39,478 --> 00:07:47,488
여기 바이너리 서치 코드가 있습니다. 실제로 바이너리 서치는 간단한 알고리즘임에도 불구하고

79
00:07:47,488 --> 00:07:53,391
모든 세부사항을 정확히 하기가 어렵다고 정평이 나있습니다.

80
00:07:53,391 --> 00:07:58,827
실제로, 한 논문에서는 처음으로 버그가 없는 바이너리 서치는 1962년에야 출간됬다고 주장합니다.

81
00:07:58,827 --> 00:08:04,430
심지어 2006년에 자바 바이너리 서치 구현에서 버그가 발견되었는데요

82
00:08:04,430 --> 00:08:09,417
알고리즘 개발에 있어서 얼마나 주의해야하는지 보여줍니다.

83
00:08:09,417 --> 00:08:15,847
특히 수백만명이 사용하는 라이브러리의 경우에는 더 그렇습니다. 여기 구현이 있습니다.

84
00:08:15,847 --> 00:08:24,048
종종 재귀적으로 구현하긴 하지만, 지금 경우에는 아닙니다.

85
00:08:24,048 --> 00:08:32,050
제가 말로 설명한것을 그대로 반영하는 코드입니다.

86
00:08:32,050 --> 00:08:41,029
키가 배열에 있는지 알려고 두 개의 포인터를 씁니다, lo, hi를 통해

87
00:08:41,029 --> 00:08:46,051
관심있는 서브 어레이에서 lo가 hi보다 작거나 같으면 

88
00:08:46,051 --> 00:08:51,053
미들을 계산합니다. 그 뒤 주어진 키를 미들과 비교해서

89
00:08:51,053 --> 00:08:56,082
실제로 비교는 세 가지 경우를 보는데요. 작은지 ,큰지, 같은지

90
00:08:56,082 --> 00:09:02,011
같다면 미들 인덱스를 반환합니다. 작다면, hi 포인터를 재조정하고, 만약 크다면, 

91
00:09:02,011 --> 00:09:07,026
lo 포인터를 재조정합니다. 포인터가 같은 값을 가질때까지 수행합니다.

92
00:09:07,026 --> 00:09:12,034
만약 lo=hi가 같은데, 그 값이 주어진 키 값과 같지 않다면 -1을 반환합니다.

93
00:09:12,034 --> 00:09:18,023
이 부등식을 생각해보면, 이 프로그램이 작동할것이라고 자신할 수 있을겁니다.

94
00:09:18,023 --> 00:09:24,025
키가 배열에 있다면, lo와 hi 사이에 있을겁니다.

95
00:09:24,025 --> 00:09:30,036
여러분에게 친숙한 프로그램이였습니다. 이제 수학적 분석을 해봅시다.

96
00:09:30,036 --> 00:09:36,039
이 정리는 증명하기에 쉽습니다.

97
00:09:36,039 --> 00:09:42,049
많은 정리 증명을 하진 않을텐데요, 이것은 쉽습니다.

98
00:09:42,049 --> 00:09:48,045
바이너리 서치는 정렬된 사이즈 N 배열에서, 최대 1+lnN만큼의 비교를 한다는 겁니다.

99
00:09:48,045 --> 00:09:55,032
그럼 일단 변수 T(N)을

100
00:09:55,032 --> 00:10:02,089
 사이즈 N 바이너리 서치에 필요한 비교 횟수라고 정의하면서 시작합니다.

101
00:10:02,089 --> 00:10:10,001
코드를 반영해주는 재귀식을 써보겠습니다.

102
00:10:10,001 --> 00:10:16,076
코드는 문제 규모를 절반으로 나눕니다. 그래서

103
00:10:16,076 --> 00:10:23,000
만약에 T(N)이 T(N/2) +1보다 작거나 같다면, 비교를 어떻게 카운트하느냐에 따라서 다르지만,

104
00:10:23,000 --> 00:10:29,045
two-way 비교라고 한다면,

105
00:10:29,045 --> 00:10:35,046
한 번 비교를 함으로써 N이 1보다 큰 한, 위에 식은 성립합니다.

106
00:10:35,046 --> 00:10:42,039
만약 N이 1이라면, 답은 1이겠죠. 계산 과정을 나타내는 재귀식을 봤습니다.

107
00:10:42,039 --> 00:10:48,094
첫번째 항에 재귀식을 반복적으로 적용함으로써,

108
00:10:48,094 --> 00:10:55,882
위 식을 풀 수 있는데요, 이 기법을 텔레스코핑이라고 합니다.

109
00:10:55,882 --> 00:11:03,378
T(N)에 대해 참이라면 T(N/2)에도 적용할 수 있고

110
00:11:03,378 --> 00:11:09,096
이런식으로 계속 적용해서

111
00:11:09,096 --> 00:11:15,340
T(1)이 될때까지 하는데, 그렇게 되면 값은 1+lnN이 됩니다.

112
00:11:15,340 --> 00:11:21,794
이게 N이 2의 제곱일때만 성립하는게 아니냐고 생각할 수 있습니다.

113
00:11:21,794 --> 00:11:29,118
N이 홀수일때의 경우를 특정하지 않았기 때문에 그럴 수 있습니다.

114
00:11:29,118 --> 00:11:36,985
그렇지만 이런 세부사항은 쉽게 관리할 수 있고

115
00:11:36,985 --> 00:11:45,649
바이너리 서치의 러닝 타임은 항상 로그함수적이라는걸 보여줄 수 있습니다.

116
00:11:45,649 --> 00:11:52,779
이 사실로 인해서, 우리는 

117
00:11:52,779 --> 00:11:58,548
더 빠른 3-sum 알고리즘을 만들 수 있습니다. 정렬 기반 알고리즘인데요.

118
00:11:58,548 --> 00:12:04,638
일단 인풋으로 주어진 숫자들을 정렬할겁니다.

119
00:12:04,638 --> 00:12:11,553
정렬 알고리즘은 다음 주에 다룰겁니다. NlnN에 비례하는 시간에 할 수 있지만,

120
00:12:11,553 --> 00:12:18,416
그게 계산의 주요 부분은 아닙니다. 주요 부분은

121
00:12:18,416 --> 00:12:25,682
숫자가 정렬된 후에, 각 숫자의 순서쌍 a[i], a[j]마다

122
00:12:25,682 --> 00:12:32,452
-(a[i]+a[j])에 대해 바이너리 서치를 할 겁니다.

123
00:12:32,452 --> 00:12:41,319
만약 그 값을 찾는다면, 위 세 값의 합이 0이 되는겁니다.

124
00:12:41,319 --> 00:12:48,610
숫자를 정렬한후에, 각 순서쌍마다 바이너리 서치를 해서

125
00:12:48,611 --> 00:12:55,631
-(-40+0)은 40이고 바이너리 서치를 해보면, 배열에 값이 있으니깐

126
00:12:55,631 --> 00:13:02,081
3-sum 문제의 해를 하나 찾았네요. 이걸 모든 순서쌍에 하는 겁니다.

127
00:13:02,081 --> 00:13:08,243
분석을 보면, 러닝타임의 증가도는 N^2lnN이라고 나오네요.

128
00:13:08,243 --> 00:13:14,064
좋은 정렬 알고리즘을 사용할 필요도 없습니다. 가장 처음 다룬 기본적인 삽입 정렬을 쓸 수 있습니다.

129
00:13:14,064 --> 00:13:20,678
각 N^2개의 순서쌍마다 바이너리 서치를 하는데 드는 시간은

130
00:13:20,678 --> 00:13:26,712
N^2lnN의 러닝 타임을 가집니다.

131
00:13:26,712 --> 00:13:32,997
퍼포먼스 개선에 대한 간단한 예를 볼 수 있습니다.

132
00:13:32,997 --> 00:13:39,970
문제를 푸는데 개선된 알고리즘을 찾을 수 있었습니다.

133
00:13:39,970 --> 00:13:46,462
N^2lnN은 N^3보다 훨씬 적은 시간이 걸립니다.

134
00:13:46,462 --> 00:13:51,872
만약 정렬을 한후, 바이너리 서치를 하는 위 과정을 한다면,

135
00:13:51,872 --> 00:13:58,257
프로그램 속도가 더 빠를겁니다. 실제 해보면,

136
00:13:58,257 --> 00:14:03,498
전에는 N이 8000이였을때 51초 걸렸던 것이

137
00:14:03,498 --> 00:14:08,858
지금은 1초가 채 걸리지 않습니다. 지금은 50초로

138
00:14:08,858 --> 00:14:15,118
64000 규모를 풀 수 있습니다. 보통  알고리즘의 증가도가 더 좋다는것을 실 상황에서의 빠름으로 기대합니다.

139
00:14:15,118 --> 00:14:21,051
실제 알고리즘 세부사항을 검사하는데 있어서는

140
00:14:21,051 --> 00:14:26,731
실제 테스트해도보고 어떤게 더 빠른지 볼 수 있습니다.

141
00:14:26,731 --> 00:14:31,893
분명히 N^3와 비교해보면 N^2lnN을 비교해보면, 우리가 더 좋은 알고리즘을 가졌다는걸

142
00:14:31,893 --> 00:14:33,003
기대할 수 있습니다.