好，我们已经看了快速合并和快速查找算法，两种算法 都很容易实现，但是不支持巨大的动态连通性问题 那么，我们该怎么改进呢？下面我们就来讲这个问题 一种非常有效的改进方法，叫做带权。也许 我们在讲这两个算法的时候你已经想到了。这个改进的想法是 在实现快速合并算法的时候执行一些操作避免得到很高的树 如果一棵大树和一棵小树合并，你会想试着 避免将大树放在下面，那将会导致更高的树 这个加权操作实现起来也相对容易。我们会跟踪 每棵树中对象的个数，然后 我们通过确保将小树的根节点作为大树的根节点的子节点以维持平衡 所以，我们避免左图中将大的树放在下面的情况 在带权算法中，我们总是将小的树放在下面 我们看应该如何实现它。首先我们来看演示。好的，我们又 从我们通常的位置开始，每个对象在自己的树中 如果只需要连接两个对象，和之前的算法是一样的 但是现在我们要将8与4和3合并，我们把8作为子节点 而不看参数的顺序如何，因为8是更小的树 6和5不影响，哪个在下面都无所谓。9和4 9那棵树小，4那棵树大。所以9在下面 2和1，5和0。5在大树中 所以0到下面。7和2，2在大树中 所以7到下面。6和1，树的大小相同。7和3 3在小树中所以3到下面。所以，带权算法总是 确保小树到下面。我们又得到了一棵包含所有对象的树 但是这次，我们有一些约束保证所有的对象不会离根节点太远 我们一会明确地分析一下这个性质 这个例子展示了对于同一组合并命令使用带权快速合并算法的效果 我们总是将小树放在下面 100个对象，88个合并操作。可以看到上面无权算法 大树中有些节点离根节点有些远。下面 使用带权算法所有节点距离根节点都在4以内 对象与根节点的平均距离小多了 我们来看一下Java实现，然后我们做一些深入的定量分析 我们在之前相同数据结构基础上，需要一个额外的数组 对于每个对象，给出以该对象为根节点的树中的对象个数 在合并操作中我们会维护这个数组。查找操作的实现 与快速合并算法中的相同，只需要检查根节点是否相同 对于合并操作的实现，我们修改代码使它检查树的大小 然后将小树的根节点连接到大树的根节点上 在改变id记录值之后，我们还要改变大小数组。如果把i变为j的子节点 我们需要给j的树的大小加上i的树的大小 反之，我们需要给i的树的大小加上j的树的大小 那么，白色背景的代码就是实现快速合并的完整代码了 并没有增加很多代码，但是性能有了很大提高。实际上我们能 从数学上分析运行时间并且证明我们定义的操作需要花费 的时间与节点在树中的深度成正比 我们可以证明树中任意节点的深度 上限是以2为底N的对数。我们使用 lg表示以2为底的对数。如果N=1000 对数是10。N是1百万，对数是20。N是10亿 对数是30。和N相比对数值非常小。我们来看它的证明 这门课中对于这种至关重要的结论我们会做数学证明 那么为什么任意节点x的深度最多是N以2为底的对数呢？ 理解这个问题的关键在于观察节点的深度到底是在何时增加的 何时它在树中变得更深？ 当x所在的树，即图中的T1，与另一棵树，即图中的T2，合并的时候x的深度加1 好，之前我们说过只有在T2的大小 T2的大小大于等于T1的大小时才会发生这种情况
所以当x深度增加时 树的大小至少翻倍。这很关键，因为这意味着 包含x的树的大小最多可以翻N次倍因为如果从1开始 翻倍lg N次，就会得到N，而最后树中总共只有N个节点 这就是任意节点x的深度最多是N以2为底的对数的粗略证明 这对于这个算法的性能有着巨大的影响 现在，除了初始化总是需要正比于N的时间，合并和 “是否连接”或查询操作需要的时间都是正比于N以2为底的对数 这个算法能成比例适应大规模问题。当N从1百万变为10亿 花费的时间从20变为30，这就比较能接受了。实现起来也很容易 我们本可以到此为止了，但是通常算法设计中 我们理解了如何获取性能，我们就会 进一步看是否能够再改进一些。这个例子中 很容易再多改进一些。这个想法就是路径压缩 当我们试图寻找包含给定节点的树的根节点时 我们需要访问从该节点到根节点路径上的每个节点 与此同时我们可以将每个节点都指向根节点 为什么不呢？所以当我们找到P的根节点之后 可以回过头来将路径上每个节点都指向根节点 这需要常数的额外代价 我们回溯一次路径找到根节点，然后再回溯一次将树展平 我们为什么不这么做呢？令人惊奇的是 我们只需要添加一行代码就能将树展平。实际上，为了只添加一行代码 我们稍做了一点改变：我们将路径上每个节点指向 它在路径上的祖父节点。这种实现不如完全展平好 实际应用中两者差不多一样好 所以，我们用了一行代码，就让树基本完全展平了 人们在想出带权之后很快就发现这个算法 而要分析这个算法则超出了我们这门课的范围 但我们这个例子很好地说明了即使简单的算法也可以有很有意思而且复杂的分析 Hopcroft Ulman和Tarjan证明了如果 有N个对象，M个合并与查找操作的任意序列，需要访问数组 最多c(N + M lg* N)次。lg* N是个挺有意思的函数 它是使N变为1需要取对数的次数 它叫做迭代对数函数。在真实世界中 可以认为是一个小于5的数，因为lg*（2^65536）=5 所以，这说明带路径压缩的带权快速合并算法 在真实世界中的时间复杂度是线性的，而实际上可以改进到 一个更有意思的函数，Ackermann函数，这个函数增长速度 比 lg* 还慢。另外一点要说明的是看起来<i></i> 这个算法的时间复杂度已经非常接近与N成正比的线性了 它与N乘一个关于N的增长非常缓慢的函数成正比。那么是否存在一个简单的算法 其时间复杂度就是线性的呢？人们找了很久，实际上最后 证明了这样的算法是不存在的。所以 在我们使用的算法背后有着很多的理论工作。了解这些理论 对我们来说是很重要的，它可以帮助我们 在实际应用中选择算法，以及告诉我们应该在何处下功夫 寻找更好的算法。并查集问题不存在线性时间算法 这个精妙的结论最终是Friedman与Sachs证明的 而在应用中，带压缩路径的带权快速合并算法 已经足够接近线性算法了，使得我们可以求解巨大的问题 好，我们总结一下求解动态连通性问题的算法 使用带路径压缩带权快速合并算法，我们能够解决其他算法不能解决的问题 例如，我之前说过如果有10亿个操作 和10亿个对象可能需要计算30年。我们现在能在 6秒内完成。需要认识到的更重要的是 是算法设计使得求解大规模问题成为可能。更快的计算机 并没有起很大作用。你可以投资上百万建造超级计算机，可能 你不需要花30年而是6年来完成，或者两个月，但是 使用快速的算法，你可以在你自己的家用电脑上用几秒钟完成