Okay. Então, nós olhamos a união rápida e rápido encontrar algoritmos. Ambos os quais são fáceis de implementar. Mas simplesmente não pode suportar uma enorme dinâmica de conectividade problemas. Então, como é que vamos fazer melhor? Isso é o que veremos a seguir. A melhoria muito eficaz, ele é chamado de ponderação. E isso pode ter ocorrido a você enquanto estamos olhando para estes algoritmos. A ideia é, quando implementação do algoritmo de união rápida tomar medidas para evitar que as árvores altas. Se você tem uma árvore de grande porte e uma pequena árvore de combinar junto o que você quer tentar a fazer é evitar colocar a árvore de grande porte menor, que vai levar a altura longa árvores. E há uma maneira relativamente fácil de fazer isso. O que nós vamos fazer é que vamos manter o controle do número de objetos em cada árvore e, em seguida, vamos manter o equilíbrio por sempre para garantir que a ligação raiz da árvore menor para a raiz do maior árvore. Então, nós, nós evitar esta situação primeiro aqui onde vamos colocar o maior árvore mais baixa. No algoritmo ponderada, colocamos sempre a menor árvore menor. Como nós, vamos ver como podemos implementar isso. Vamos ver uma demonstração primeiro. Ok, então novamente começa em nossa posição normal de partida, onde todo mundo está em sua própria árvore. E para quando há apenas dois itens para ligar, ele funciona, funciona da mesma maneira como antes. Mas agora, quando nós temos de oito a fundir-se com quatro e três, colocamos a oito como a criança, , não importa que ordem os seus argumentos veio, porque é a mais pequena árvore. Assim, seis e cinco não importa, qualquer um vai para baixo não importa. Nove e quatro, agora, nove é o pequeno quatro é um dos grandes. Assim, nove vai ser o único que vai abaixo. Dois e um, cinco e zero. Então, agora, cinco e zero-cinco está na a árvore maior, então vai de zero abaixo. Sete e dois, dois é na maior árvore de forma sete vai abaixo. Seis e um que está em árvores de tamanho igual. E sete e três, três é menor na árvore de modo que passa por baixo. Assim, o algoritmo ponderada sempre garante que a árvore menor vai abaixo. E, novamente, nós terminamos com um único árvore que representa todos os objetos. Mas, desta vez, nós h av alguma garantia de que não item é muito longe da raiz e vamos conversar sobre isso explicitamente em um segundo. Então, aqui está um exemplo que mostra o efeito de fazer a união ponderada rápida onde colocamos sempre a menor árvore abaixo para o mesmo conjunto de comandos sindicais. Isto é, com uma centena de sites e 88 operações de união. Você pode ver no topo da grande árvore tem algumas árvores, alguns nós, uma distância razoável da raiz. Na parte inferior, por algoritmo ponderado todos os nós estão à distância de quatro a partir da raiz. O distância média da raiz é muito, muito menor. Vamos olhar para o Java implementação e então veremos em mais detalhe menos, no que quantitativa informações. Então, usamos a mesma estrutura de dados, exceto, agora precisamos de um extra matriz, que, para cada item, fornece o número de objetos na árvore encaminhado em esse item. Isso vai manter na operação de união. Encontre implementação é idêntico ao de união rápida, você está apenas verificando se as raízes são iguais. Para implementação da união, vamos modificar o código para verificar os tamanhos. E ligação raiz da árvore menor para a raiz da árvore maior, em cada caso. E então depois de alterar a ligação id, nós também alterar o tamanho de matriz. Se fizermos id, ia criança de j, então temos que incrementar o tamanho da árvore j pelo tamanho da árvore do i. Ou se nós fazemos o contrário, então temos que incrementar o tamanho do i da árvore por tamanho da árvore de j. Então, esse é o código completo em branco para a implementação rápida união. Então, não o código muito, mas o desempenho muito, muito melhor. Na verdade, podemos analisar o tempo de execução matematicamente e mostrar que operação definida, leva tempo proporcional ao quão longe as árvores estão no nó na árvore, o nós estão na árvore, mas podemos mostrar que é garantido que a profundidade de qualquer nó da árvore é, no máximo, o logaritmo para a base de dois dos N. Usamos a notação Lg sempre para logaritmo na base dois. E, e, até então, se N é um mil, que vai ser 10, se N é um milhão que é 20, se N é um bilhões, que é 30. É um número muito pequeno comparado a N. Então, vamos olhar para a prova disso. Nós fazer algumas provas matemáticas de, neste curso, quando eles são críticos como este um. E por que é verdade que a profundidade de qualquer nó x é, no máximo, faça o login base dois de N? Bem, a chave para a compreensão de que é, dê uma olhada exatamente quando é que a profundidade de qualquer aumento nó? Quando ele vai ainda mais para baixo na árvore? Bem. O x da profundidade vai aumentar em um, quando a sua árvore, T1 neste diagrama, é mesclado em algum outro árvore, T2 neste diagrama. Bem, nesse ponto nós disse que só faria isso se o tamanho de T2 foi maior do que a ou igual ao tamanho de T1. Assim, quando a profundidade de x aumenta, do tamanho da sua árvore, pelo menos duplos. Então, essa é a chave, porque isso significa que o tamanho da árvore contendo x pode dobrar no máximo log N vezes, porque se você começar com um duplo e log N vezes, você começa N e só há N nós na árvore. Assim, que é um esboço de uma prova de que a profundidade de qualquer nó x é a base mais log dois N. E isso tem um impacto profundo sobre o desempenho deste algoritmo. Agora, em vez da inicialização sempre leva tempo proporcional a N. Mas agora, tanto o sindicato ea operação conectado ou encontrar leva tempo proporcional ao log base dois de N. E isso é um algoritmo que escalas. Se N cresce de um milhão para um bilhão, que custo vai de 20 a 30, que é completamente inaceitável. Agora, isso foi muito fácil de implementar e, e nós poderíamos parar, mas, geralmente, o que acontece no projeto de algoritmos é agora que entendemos o que é que o desempenho de ganhos, vamos dar uma olhar e ver, bem, podemos melhorá-lo ainda mais. E, neste caso, é muito fácil de melhorar muito, muito mais. E essa é a idéia de compressão caminho. E idéia é que, bem, quando estamos a tentar encontrar a raiz da árvore contendo um, um determinado nó. Estamos tocando todos os nós no caminho desse nó para a raiz. Enquanto estamos doi ng que podemos muito bem fazer com que cada um dos que apenas um ponto para o raiz. Não há nenhuma razão para não. Então, quando nós estamos procurando, nós estamos tentando encontrar o raiz, de P. Depois de encontrá-lo, que pode muito bem voltar atrás e fazer cada nó nesse caminho apenas apontar para a raiz. Isso vai ser um custo constante extra. Fomos até uma vez o caminho para encontrar a raiz. Agora, vamos novamente para apenas achatar a árvore fora. E o motivo seria, não há razão para não fazer isso. Tivemos uma linha de código para achatar a árvore, surpreendentemente. Na verdade, para fazer um código de um forro, usamos um, uma simples variante onde fazemos todos os outros nódulos no ponto de caminho para a sua avô no caminho até a árvore. Agora, isso não é tão bom como totalmente achatamento realmente na prática que, na verdade, é quase tão bom. Assim, com uma linha de código, podemos manter as árvores quase totalmente plana. Agora, esta pessoas algoritmo descobriu muito cedo depois de descobrir a ponderação e acaba por ser fascinante para analisar completamente fora de nosso alcance. Mas dissemos exemplo para ilustrar esta como até mesmo um algorithmah simples, pode ter interessante e análise complexa. E o que foi provado por Hopcroft Ulman e Tarjan era que se você tem N objetos, qualquer seqüência de M união e as operações de localização irá tocar o matriz na maioria das ac (N + M lg estrela N) vezes. E agora, a LG N é uma espécie de função de engraçado. É o número de vezes que você tem que ter o registro de N para obter um. E o caminho para pensar, ele é chamado a função de log iterado. E no mundo real, é melhor de pensar que, um número menor que cinco, porque dois lg ^ 65536 é cinco. Assim, que significa que o tempo de execução de união rápida ponderada com compressão caminho vai ser linear no mundo real e, na verdade, poderia ser melhorado até mesmo para um mais função interessante chamada função de Ackermann, o que é ainda mais lentamente crescente de  lg. E outro ponto sobre isso é que  parece que este é tão perto de ser linear, que é proporcional à t ime N em vez de tempo proporcional a N vezes a função crescendo lentamente em N. Existe um algoritmo simples que é linear? E as pessoas, olhou por um longo tempo para isso, e realmente funciona a ser o caso que se pode provar que não existe tal algoritmo. Então, há uma monte de teoria que vai atrás dos algoritmos que usamos. E é importante para nós saber que a teoria e que vai nos ajudar a decidir como escolher qual algoritmos que vamos utilizar na prática, e onde se concentram nosso esforço em tentando encontrar algoritmos melhores. É fato surpreendente que acabou por ser provado por Friedman e Sachs, que não existe qualquer algoritmo de tempo linear para a união encontram problema. Mas a união rápida ponderada com compressão caminho na prática é, está perto bastante que vai permitir a solução de problemas enormes. Então, esse é o nosso resumo de algoritmos para resolver o problema de conectividade dinâmica. Com o uso de união ponderada rápido e com compressão de caminho, podemos resolver problemas que não poderiam ser abordados. Por exemplo, se você tem um bilhão de operações e um bilhão de objetos que eu disse antes, pode levar 30 anos. Nós podemos fazê-lo em seis segundos. Agora, eo que é mais importante para reconhecer sobre isso é que sua concepção algoritmo que permite que a solução para o problema. Um computador mais rápido não ajudaria muito. Você pode gastar milhões em um super computador, e talvez você poderia fazê-lo em seis anos em vez de 30, ou em dois meses, mas com um rápido logaritmo, você pode fazê-lo em segundos, em segundo no seu próprio PC.