良いでしょう。私たちは高速な
UnionおよびFindアルゴリズムを見てきました。 どちらも実装は簡単ですが、巨大な
接続問題をサポートできません。 では、どのように改善したら良いでしょうか？
それを次に見ていきます。 非常に効果的な改善案は、重み付けと
呼ばれるものです。このコースのような アルゴリズムの講義を見ると
出会っていたかもしれませんね。考え方としては、 高速なUnionアルゴリズムを実装する際に
段階を踏んで、高い木を作らないようにすることです。 大きな木と小さな木とを接続させるとき、 試したいことは大きな木を下に
付けないようにすることです。こうすることで、 長く高い木を作らないようにします。これを実装するのには
比較的簡単なやり方があります。 付いているオブジェクトの数をそれぞれの木で追跡しておき、
バランスを維持するようにします。 小さい方の木のルートを大きい方の木のルートに
必ず接続するようにすることで実現します。 これで、私たちは最初の状況、
大きい方の木が下に来る、という状況を 回避できます。重み付け
アルゴリズムでは、常に小さい木が下に来ます。 では、どのように実装するのかを見てみましょう。
まずデモを見ましょう。 最初は通常の開始状態と同じところから始めます。
それぞれが自分自身の木にいます。 2つのアイテムしか接続しない場合は、
従来と同じように動きます。 しかし、ここで要素8を4と3に接続する際には、
8を子にします。 引数順に関係なく、8の方が小さい木だからです。 6と5の接続は問題ないですね。どちらが
下でも問題ありません。 9と4ですが、9の方が小さい木で、
4の方が大きい木ですから、9が下に置く木になります。 2と1、5と0。ここで、5の方が大きい木ですから、 0が下に来ます。7と2ですが、
2の方が大きい木ですので7が下に来ます。 6と1ですが、これらは同じ大きさの木ですね。 そして7と3ですが、3の方が小さい木ですので、
下につきます。このように、重み付けアルゴリズムでは 小さい方の木が必ず下に配置されます。ここで、再び すべてのオブジェクトを表現する1本の木に巻き取りましたが、
今度は、ある保証があります。 つい先ほどお話ししたとおり、ルートから
遠く離れた要素は存在しない、ということです。 これが、重み付け高速Unionを行った効果を示した例です。 ここでは、同じUnionコマンドを行った際に、
小さい方の木が常に下に置かれるようになっています。 これは100のサイトに88回Union操作を
行ったものです。上の例では 大きな木があり、中に少しの木とノードがあり、
ルートからとても離れていますね。 下の例では、重み付けアルゴリズムの場合で、ノードは
すべてルートから4の距離までしか離れていません。 ルートからの平均距離はずっとずっと小さいのです。 Javaの実装を見て、詳しいところを、
定量的な情報を見てみましょう。 私たちは同じデータ構造を使いますが、
今回は追加の配列が必要です。 これは、各要素について、その要素に
到達するまでのツリー内のオブジェクト数を与えます。 この配列がunion操作を管理します。
findの実装は 高速unionと同じです。ルートが同一か
どうかをチェックするだけです。 union操作については、サイズを
チェックするコードを変更します。 それぞれの場合で、小さい方の木のルートを
大きい方の木のルートに接続します。 idのリンクを変更した後、size配列も変更します。 idを i から j の子に変更したら、
j の木のサイズを i の木のサイズだけ増やします。 逆の場合では、i の木のサイズを
j の木のサイズ分だけ増やす必要があります。 白地になっているところが
高速union全体のコードです。 それほどコードは大きくないですが、
ずっと良いパフォーマンスが得られます。 実際、数学的に実行時間を分析できます。 定義した操作を行う時間は、ノードがどれだけ
木の深い位置にあるかに比例しますが どのノードも木の深さが高々底が２のlogNに 収まることが保証されていることが分かります。 ここでlgは底が２のlogを常に表します。 ですので、Nが1000なら10ですし、
百万なら20、10億なら30です。 Nに比べれば非常に小さな数です。
ではこの証明を見てみましょう。 このコースでは、時々数学的証明をします。
今回のように重要な場面では。 なぜ、どのノードxについても高さが
高々底が２のlogNになるのでしょうか。 理解する鍵は、任意のノードの深さが
増加するのはどんなときなのか どんなときに木を深くたどることに
なるのかを正確に見ていくことです。 この図に示すT1という木が他の木に
結合するとき、Xの深さは1増加します。 この図ではT2ですね。このとき、T2の大きさが
T1より大きいか等しいときときだけ 結合が行われると言えます。
ですので、Xの深さが増加するときには 木のサイズは少なくとも2倍になります。ここが鍵です。 Xを含む木のサイズは、最大でもlogN回で
倍になります。なぜなら 1から始めてlogN回だけ2倍していけばNに到達し、
木にはN個のノードしかないことになるからです。 これが任意のノードXの深さは高々底が２の
logNだという大まかな証明の流れです。 この事実が、このアルゴリズムの性能に
深い影響を与えています。 ここで、初期化は常にNに比例する時間がかかりますが、 union、結合、find操作は底が２のlogNに比例します。 これがスケールできるアルゴリズムです。
Nが100万から10億に増えたとしても、 計算コストは20から30に増えるだけです。
これならとても受け入れられるものです。 さて、このアルゴリズムは実装が
とても簡単で実行もすぐ終わりますが、 通常はアルゴリズムのデザインを変えると、
性能を上げることができるということが理解できます。 このアルゴリズムを見直すと、
さらに良くできるだろうと思います。 この場合、もっとずっと簡単に改良できます。
そのアイディアはパス圧縮です。 このアイディアとは、与えられた
ノードを含んだ木のルートを探そうとするとき、 そのノードからルートまでの
すべてのノードを触っています。 その際に、通った各ノードがルートを
指すようにしてしまうのが良いでしょう。 そうしない理由もないですから。
ですので、ノードPのルートを探そうと検索しているとき、 探し終わった後でそのまま戻って、 パス上のノードはすべてルートを指すようにします。
一定量の追加コストはかかるでしょうが、 いったんルートを見つけたら
パスを持ち上げて、木をより平坦にしていきます。 そうしないでおく理由がないでしょう。 驚くことに、木を平坦化するための
コードは1行です。実際、1行のコードで 1つの変数だけで、パス内の他のノードすべてを 2世代前のノードを指すようにできます。
実際には、全体を平坦化するよりは良くないですが、 十分良いものです。 このように、1行足すだけで
木を概ね完全に平坦化できます。 このアルゴリズムを、人々は
重み付けアルゴリズムを発見してから比較的早く見つけ出し かなり本コースの範囲を外れるほど
解析がイライラするものだと判明していますが、 この例に触れることで、簡単な
アルゴリズムであっても 面白く、複雑な解析が必要なものに
なることを示しました。Hopcroft,Ulman,Tarjanによると、 N個オブジェクトがある場合、M個のunion-find操作をすると 配列を高々c(N+Mlg*N)回しか
触らないことが証明されています。 lg*Nは変わった関数で、logN個の中から
1を取得するのにかかる回数を指します。 これを反復log関数と呼びます。
実世界では、 この値は5より小さいと考えておくのが最善です。
なぜなら、lg*2の65536乗が5だからです。 ですので、重み付け高速Unionで、
パス圧縮を施した方式の実行時間は、 実世界では線形になるでしょう。 そして、もっと興味深いアッカーマン関数と
呼ばれる関数まで改良できるでしょう。 この関数はlg*よりもずっと
遅くしか値が増えていきません。<i>もう１つのポイントは、</i> このアルゴリズムは線形に近づいてきているので、
N×時間に比例するようになるように見えます。 成長の遅い関数×Nではなくて、です。
線形になる簡単なアルゴリズムがあるでしょうか。 人々は、長い時間それを探していて、 そのようなアルゴリズムは実際には
存在しないことが証明できました。 ですので、私たちが使っているアルゴリズムの
背後にはたくさんの理論があり、 その理論を知ることは重要であり、
実際どのアルゴリズムを選べば良いか、 どこにより良いアルゴリズムを用いようと
努力を傾けるかを決める手助けになります。 FriedmanとSachsによって、
このunion-find問題を解くアルゴリズムに 線形時間で終わるものがないと
証明されたのは驚きです。 しかし、パス圧縮付きの
重み付けアルゴリズムは実用上は 巨大は問題を解くことができる
ようになるには十分です。 では、動的接続問題を解く
アルゴリズムについてのまとめです。 重み付けアルゴリズムとパス圧縮を用いると、
他のアルゴリズムでは 対応ができなかった問題を解くことができます。
たとえば、10億個オブジェクトがあって 10億回操作があった場合、
前に述べたように、30年かかるでしょう。 それを６秒で行うことができます。
このアルゴリズムについて認識する上で最も重要なことは、 アルゴリズムのデザイン如何で
問題を解くことができる、ということです。 高速なコンピュータを持ってきても
あまり役に立ちません。スパコンを数百万台使って良いなら 30年かかるところを6年でできるかもしれません。
あるいは2ヶ月とかかもしれませんね。 しかし、高速なアルゴリズムを用いれば
皆さんのPCでも数秒で解くことができるのです。