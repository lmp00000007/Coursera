1
00:00:02,041 --> 00:00:07,088
Мы рассмотрели алгоритмы
быстрого объединения и поиска.

2
00:00:07,088 --> 00:00:13,034
Оба просты в реализации,
но не могут поддерживать большие задачи динамической

3
00:00:13,034 --> 00:00:18,151
связности. Как сделать их лучше?
Рассмотрим этот вопрос.

4
00:00:18,151 --> 00:00:23,731
Одно из улучшений называется взвешиванием.
Вы могли догадаться о нем,

5
00:00:23,731 --> 00:00:28,764
когда мы рассматривали алгоритмы.
Идея в том,

6
00:00:28,764 --> 00:00:34,735
чтобы при реализации быстрого объединения
избежать высоких деревьев.

7
00:00:34,735 --> 00:00:41,873
Есть большое и малое дерево
для объединения, постарайтесь

8
00:00:41,873 --> 00:00:48,184
не помещать большое дерево ниже,
чтобы не получить высокое дерево.

9
00:00:48,184 --> 00:00:54,376
Для этого есть относительно простой способ.
Будем отслеживать

10
00:00:54,376 --> 00:01:00,577
количество объектов в каждом дереве
и следить за тем,

11
00:01:03,558 --> 00:01:05,049
чтобы корень малого дерева был соединен
с корнем большого дерева.

12
00:01:06,539 --> 00:01:12,176
Таким образом можно избежать ситуацию,
при которой высокое дерево оказывается

13
00:01:12,176 --> 00:01:18,053
внизу. Во взвешенном алгоритме
мы всегда ставим меньшее дерево ниже.

14
00:01:18,053 --> 00:01:27,470
Посмотрим на реализацию. Сначала демо.
Начинаем со стартовой

15
00:01:27,470 --> 00:01:34,790
позиции, когда каждый
в своем собственном дереве.

16
00:01:35,059 --> 00:01:42,249
Когда нужно объединить только 2 элемента,
то всё работает как обычно.

17
00:01:42,249 --> 00:01:48,725
Но если мы объединяем 8 с 4 и 3,
то делаем 8 наследником

18
00:01:48,725 --> 00:01:56,408
независимо от порядка аргументов,
потому что это меньше дерево.

19
00:01:56,408 --> 00:02:02,368
6 и 5: не важно какое дерево идет ниже.
9 и 4:

20
00:02:02,368 --> 00:02:09,710
сейчас 9 — это меньшее дерево, 4 — большее.
Тогда 9 становится ниже.

21
00:02:09,710 --> 00:02:20,136
2 и 1, 5 и 0. 5 — большее дерево, тогда 0

22
00:02:20,136 --> 00:02:33,812
идет вниз. 7 и 2, 2 — большее дерево, 

23
00:02:33,812 --> 00:02:46,129
тогда 7 идет ниже. 6 и 1 находятся
в деревьях одного размера. 7 и 3:

24
00:02:46,129 --> 00:02:59,272
3 в меньшем дереве т.е. становится ниже.
Взвешенный алгоритм

25
00:02:59,272 --> 00:03:08,686
гарантирует, что меньшее дерево будет ниже.
И снова мы получили одно дерево

26
00:03:08,686 --> 00:03:15,571
со всеми объектами. Но в этот раз
есть гарантия, что ни один объект не будет

27
00:03:15,571 --> 00:03:21,267
слишком далеко от корня.
Поговорим об этом чуть позже.

28
00:03:21,267 --> 00:03:27,980
Вот пример взвешенного
быстрого объединения,

29
00:03:27,980 --> 00:03:35,236
в котором мы всегда помещаем меньшее
дерево вниз.

30
00:03:35,236 --> 00:03:42,939
Здесь 100 объектов и 88 операций объединения.
Видим вверху большое

31
00:03:42,939 --> 00:03:49,768
дерево, имеющее некоторые узлы
далеко от корня.

32
00:03:49,768 --> 00:03:55,908
Внизу все узлы находятся
на расстоянии 4 или менее.

33
00:03:55,908 --> 00:04:01,207
Среднее расстояние к корню намного меньше.
Теперь посмотрим на Java

34
00:04:01,207 --> 00:04:06,557
реализацию, а затем рассмотрим
более детально количественные

35
00:04:06,557 --> 00:04:12,286
показатели. Мы использовали
ту же структуру данных, но в этот раз нам нужен дополнительный массив,

36
00:04:12,286 --> 00:04:17,569
содержащий для каждого элемента
количество объектов

37
00:04:17,569 --> 00:04:22,971
его дерева. Это пригодится
для операции объединения. Операция поиска 

38
00:04:22,971 --> 00:04:28,589
идентична быстрому поиску —
вы просто проверяете равны ли корни.

39
00:04:28,589 --> 00:04:34,009
Для реализации объединения изменим
код для проверки размера.

40
00:04:34,009 --> 00:04:40,118
Соединим корень меньшего дерева
с корнем большего в каждом случае.

41
00:04:40,118 --> 00:04:46,049
После изменения id мы также меняем
массив размеров. Устанавливаем i

42
00:04:46,049 --> 00:04:52,241
наследником j и увеличиваем
размер дерева j на размер дерева i.

43
00:04:52,241 --> 00:04:58,495
Или наоборот —
увеличиваем размер дерева i

44
00:04:58,495 --> 00:05:04,849
на размер дерева j. Белым выделен
код для реализации быстрого

45
00:05:04,849 --> 00:05:12,424
объединения. Немного кода, но гораздо
лучшая производительность.

46
00:05:12,424 --> 00:05:19,194
Можно проанализировать время работы математически.
Описанная операция занимает

47
00:05:19,194 --> 00:05:25,225
время пропорциональное расстоянию
от узла до корня дерева,

48
00:05:25,225 --> 00:05:31,445
но можем показать,
что максимальная "глубина"

49
00:05:31,445 --> 00:05:37,989
любого узла в дереве не превышает
логарифма по основанию 2 от N.

50
00:05:37,989 --> 00:05:43,974
Обозначение Lg используем для логарифма
по основанию 2. Для N = 1000,

51
00:05:43,974 --> 00:05:49,246
lg равен 10, для миллиона — 20.
Для миллиарда —30.

52
00:05:49,246 --> 00:05:55,745
Очень маленькие числа по сравнению c N.
Рассмотрим доказательство.

53
00:05:55,745 --> 00:06:02,046
В курсе мы приводим математические доказательства,
там где они необходимы.

54
00:06:02,046 --> 00:06:07,981
Почему верно, что "глубина" любого узла x
не больше, чем Lg(N)?

55
00:06:07,981 --> 00:06:13,850
Чтобы понять это, нужно
рассмотреть, как имено 

56
00:06:13,850 --> 00:06:21,347
растет глубина узла. Когда оно опускается
по дереву? Глубина x

57
00:06:21,347 --> 00:06:29,697
увеличится на 1, когда его дерево —
T1 на диаграмме — объединится с другим

58
00:06:29,697 --> 00:06:37,835
деревом — T2 на диаграмме.
Это происходит, только если размер

59
00:06:37,835 --> 00:06:45,331
T2 больше или равен T1.
Т.е. когда глубина x увеличивается,

60
00:06:45,331 --> 00:06:52,662
размер его дерева
как минимум удваивается. Значит,

61
00:06:52,662 --> 00:06:58,305
размер дерева, содержащего x,
может удваиваться не более lg(N) раз,

62
00:06:58,305 --> 00:07:05,205
ведь умножая 1 на lg(N), получаем N —
количество узлов.

63
00:07:05,205 --> 00:07:11,631
Это примерное доказательство того,
что глубина любого узла x не более чем lg(N).

64
00:07:11,631 --> 00:07:18,605
И это сильно влияет
на производительность алгоритма.

65
00:07:18,605 --> 00:07:24,548
Инициализация всегда занимает время,
пропорциональное N. Но теперь и объединение

66
00:07:24,548 --> 00:07:31,010
и поиск занимают время,
пропорциональное логарифму от N по основанию 2.

67
00:07:31,010 --> 00:07:37,477
И такой алгоритм масштабируется.
Если N вырастает с миллиона до миллиарда,

68
00:07:37,477 --> 00:07:43,668
то затраты увеличиваются с 20 до 30,
что достаточно приемлемо. На этом можно было бы

69
00:07:43,668 --> 00:07:50,089
остановиться, но как обычно
происходит при разработке

70
00:07:50,089 --> 00:07:57,004
алгоритмов, теперь мы понимаем,
за счет чего можно улучшить производительность,

71
00:07:57,004 --> 00:08:02,075
и стараемся ещё улучшить алгоритм.
В данном случае

72
00:08:02,075 --> 00:08:09,072
это легко сделать. Воспользуемся идеей
уплотнения пути.

73
00:08:09,072 --> 00:08:17,066
Пока мы пытаемся найти
корень дерева, содержащего 

74
00:08:17,066 --> 00:08:24,361
заданный узел, мы проходим все узлы
на пути от заданного до корня.

75
00:08:24,568 --> 00:08:30,422
Мы можем все их связать с корнем.

76
00:08:30,422 --> 00:08:37,299
Нет причин не делать это. Мы ищем корень P, 

77
00:08:37,299 --> 00:08:43,580
а после этого проходим обратно
и указываем каждому узлу 

78
00:08:43,580 --> 00:08:51,046
на корень. От этого
будут дополнительные затраты.

79
00:08:51,046 --> 00:08:57,088
Мы прошли по пути, чтобы найти корень.
Теперь пройдем снова, чтобы сжать

80
00:08:57,088 --> 00:09:03,099
дерево. Нет причин
не сделать этого. Всего лишь

81
00:09:03,099 --> 00:09:10,016
с помощью одной строки кода.
Чтобы написать такой код,

82
00:09:10,016 --> 00:09:15,058
используем простой вариант
с присвоением каждому узлу

83
00:09:15,058 --> 00:09:19,885
наследования.
Это не так хорошо, как полное

84
00:09:21,000 --> 00:09:26,077
сжатие, но достаточно хорошо.
Одной строкой

85
00:09:26,077 --> 00:09:32,555
кода можем сделать наше дерево
практически полностью плоским.

86
00:09:32,828 --> 00:09:41,987
Алгоритма был открыт довольно давно,
после открытия взвешенности,

87
00:09:41,987 --> 00:09:49,588
он оказался весьма интересным для анализа,
но это вне рамок курса.

88
00:09:49,588 --> 00:09:55,749
Мы проиллюстрировать, что даже простой
алгоритм может иметь интересный

89
00:09:55,749 --> 00:10:02,203
и сложный анализ.
Хопкрофт, Ульман и Тарьян доказали:

90
00:10:02,203 --> 00:10:07,792
если имеется N объектов и M операций
объединения и поиска,

91
00:10:07,792 --> 00:10:16,014
то обращений к массиву будет не более c(N + M lg*N).
lg*N — интересная функция.

92
00:10:16,248 --> 00:10:22,067
Столько раз нужно взять логарифм от N,
чтобы получить 1.

93
00:10:22,067 --> 00:10:28,061
Такая функция называется итерационным логарифмом.
В реальных задачах

94
00:10:28,061 --> 00:10:36,126
лучше всего считать что это число меньше 5,
т.к lg 2 от 65536 это 5.

95
00:10:36,126 --> 00:10:42,528
Значит, время работы взвешенного
быстрого объединения с сжатием пути

96
00:10:42,784 --> 00:10:49,990
будет линейным в реальных задачах. Оно может быть улучшено ещё больше.

97
00:10:49,990 --> 00:10:56,504
Функция Акермана растет ещё медленнее, 

98
00:10:56,504 --> 00:11:03,611
чем lg*<i></i>.
Замечу, что функция кажется

99
00:11:03,611 --> 00:11:09,813
очень близкой к линейной пропорции
от N вместо произведения

100
00:11:09,813 --> 00:11:15,925
N и медленно растущей функции от N.
Существует ли простой линейный

101
00:11:15,925 --> 00:11:22,008
алгоритм? Люди долгое время искали такой.

102
00:11:22,008 --> 00:11:27,700
Можно доказать, что такого алгоритма нет. 

103
00:11:27,700 --> 00:11:32,502
За рамками наших алгоритмов
большое количество теории,

104
00:11:32,502 --> 00:11:38,022
которую важно знать. Она поможет выбрать

105
00:11:38,022 --> 00:11:43,480
нужный алгоритм, который будет использован

106
00:11:43,480 --> 00:11:48,796
на практике. Фридман и Сакс доказали
удивительный факт,

107
00:11:48,796 --> 00:11:54,181
что нет линейного алгоритма для задачи
объединения и поиска.

108
00:11:54,181 --> 00:12:00,293
Но взвешенное быстрое объединение
со сжатием пути на практике

109
00:12:00,293 --> 00:12:05,844
близок и дает возможность решать
трудоемкие задачи.

110
00:12:05,844 --> 00:12:11,713
Это краткий обзор алгоритмов
динамической связности.

111
00:12:11,713 --> 00:12:17,128
Благодаря взвешенному алгоритму быстрого
объединения со сжатием пути можно решать задачи,

112
00:12:17,128 --> 00:12:23,109
не имеющие других решений.
Я приводил пример с миллиардом операций

113
00:12:23,109 --> 00:12:28,845
и объектов, что могло бы занять 30 лет.
Мы можем решить

114
00:12:28,845 --> 00:12:34,212
задачу за 6 секунд.
Важно понимать, что именно

115
00:12:34,212 --> 00:12:40,012
алгоритм помогает в решении задачи.
Быстрый компьютер

116
00:12:40,012 --> 00:12:45,529
не при чем. Можно потратить
миллионы на суперкомпьютер

117
00:12:45,529 --> 00:12:51,165
и сократить время решения с 30 лет до 6
или даже до 2 месяцев.

118
00:12:51,165 --> 00:13:02,056
А благодаря алгоритму всё решается
за секунды на домашнем ПК.